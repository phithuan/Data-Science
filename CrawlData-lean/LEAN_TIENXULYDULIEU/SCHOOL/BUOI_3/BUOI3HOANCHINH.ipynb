{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import unicodedata # 1\n",
    "import contractions # 2\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "#Thư viện Natural Language Toolkit (tạm dịch là Bộ công cụ Ngôn ngữ Tự nhiên, viết tắt NLTK) là một nền tảng dẫn đầu để xây dựng các chương trình Python làm việc với dữ liệu ngôn ngữ của con người"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['thuan', 'wa', 'and', 'han', 'to', 'then', 'do', 'not', 'know', 'what', 'you', 'are', 'talking', 'about']\n",
      "['thuan', 'wa', 'and', 'han', 'to', 'then', 'do', 'not', 'know', 'what', 'you', 'are', 'talk', 'about']\n",
      "thuan han know talk\n"
     ]
    }
   ],
   "source": [
    "def preprocess_text(text, remove_digits=True):\n",
    "    # 1. Loại bỏ ký tự có dấu (viet nam) và chuyển về chữ lower\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    text = text.lower()\n",
    "\n",
    "    # 2. Expand contractions tìm và thay thế các từ viết tắt trong văn bản bằng phiên bản đầy đủ của từ hoặc cụm từ đó. Ví dụ: \"I'm\" sẽ được mở rộng thành \"I am\".\n",
    "    text = contractions.fix(text)\n",
    "\n",
    "    # 3. Remove special characters (bỏ kí tự đặc biệt)\n",
    "    pattern = r'[^a-zA-Z0-9\\s]' if not remove_digits else r'[^\\w\\s]'\n",
    "    text = re.sub(pattern, '', text)\n",
    "\n",
    "    # 4. Text lemmatization ()\n",
    "    lemmatizer = WordNetLemmatizer() # áp dụng phương pháp lemmatize của WordNetLemmatizer cho mỗi từ.\n",
    "    words = [lemmatizer.lemmatize(word) for word in nltk.word_tokenize(text)] #nltk.word_tokenize(text): Hàm này chia văn bản thành danh sách các từ (token).\n",
    "    print(words)\n",
    "\n",
    "    # 5. Text stemming (là một kỹ thuật trong xử lý ngôn ngữ tự nhiên, được sử dụng để giảm các từ về dạng gốc của chúng. Ví dụ, từ “builds”, “building” và “built” sẽ được đưa về dạng gốc “build”\n",
    "    stemmer = PorterStemmer()\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "    print(words)\n",
    "\n",
    "    # 6. Remove stopwords trong tiếng Anh bao gồm \"the,\" \"and,\" \"of,\" \"in,\" \"to,\" và nhiều từ khác. Tuy nhiên, danh sách stopwords có thể thay đổi tùy theo ngữ cảnh\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word.lower() not in stop_words]\n",
    "\n",
    "    # Loại bỏ từ không phổ biến (ví dụ: từ có độ dài ít hơn 3)\n",
    "    words = [word for word in words if len(word) > 2]\n",
    "\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Sử dụng hàm trên với một ví dụ\n",
    "example_text = \"Thuận was and Hân to then don't know what you're talking about\"\n",
    "processed_text = preprocess_text(example_text)\n",
    "print(processed_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my wa system keep crash hi crash yesterday, our crash daili'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def simple_stemmer (text):\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    text = ' '.join([ps.stem(word) for word in text.split()])\n",
    "    return text\n",
    "simple_stemmer(\"My was system keeps crashing his crashed yesterday, ours crashes daily\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
