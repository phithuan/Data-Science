{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Admin\\Desktop\\GKD\\Data-science-GitHub\\CRAWL_DATA_LEAN\\venv\\LEAN_TIENXULYDULIEU\\SCHOOL\\lab3.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Admin/Desktop/GKD/Data-science-GitHub/CRAWL_DATA_LEAN/venv/LEAN_TIENXULYDULIEU/SCHOOL/lab3.ipynb#W0sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mre\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/Desktop/GKD/Data-science-GitHub/CRAWL_DATA_LEAN/venv/LEAN_TIENXULYDULIEU/SCHOOL/lab3.ipynb#W0sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Admin/Desktop/GKD/Data-science-GitHub/CRAWL_DATA_LEAN/venv/LEAN_TIENXULYDULIEU/SCHOOL/lab3.ipynb#W0sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcv2\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/Desktop/GKD/Data-science-GitHub/CRAWL_DATA_LEAN/venv/LEAN_TIENXULYDULIEU/SCHOOL/lab3.ipynb#W0sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/Desktop/GKD/Data-science-GitHub/CRAWL_DATA_LEAN/venv/LEAN_TIENXULYDULIEU/SCHOOL/lab3.ipynb#W0sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "import os\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_urls = ['https://notes.ayushsharma.in/technology',\n",
    "             'https://www.ayush.nz/video-games'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "response = requests.get(seed_urls[0])# G·ª≠i y√™u c·∫ßu GET ƒë·∫øn trang web v√† l·∫•y n·ªôi dung ƒë·∫ßu ti√™n\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "response1 = requests.get(seed_urls[1])# G·ª≠i y√™u c·∫ßu GET ƒë·∫øn trang web v√† l·∫•y n·ªôi dung ƒë·∫ßu ti√™n\n",
    "print(response1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import requests\\nfrom bs4 import BeautifulSoup\\nimport pandas as pd\\n\\nseed_urls = [\\n    'https://notes.ayushsharma.in/technology',\\n    'https://www.ayush.nz/video-games'\\n]\\n\\ndef build_dataset(seed_urls):\\n    news_data = []\\n    for url in seed_urls:\\n        news_category = url.split('/')[-1]\\n        data = requests.get(url)\\n        soup = BeautifulSoup(data.content, 'html.parser')\\n        tables = soup.find_all('div',class_= 'col')\\n        for id, i in enumerate(tables):\\n            title = i.find_all('h5',class_='card-title')\\n            excerpt = i.find_all('small', class_ = 'card-text')\\n            pub_date = i.find_all('div', class_ = 'card-footer text-end')\\n            if title and excerpt and pub_date:\\n                title_position = title[0].text.strip()\\n                excerpt_position = excerpt[0].text.strip()\\n                date_published = pub_date[0].text.strip()\\n                news_data.append([title_position, excerpt_position, date_published, news_category])\\n        df = pd.DataFrame(news_data,columns=['title', 'excerpt', 'pub_date', 'category'])\\n    return df\\n\\n# G·ªçi h√†m ƒë·ªÉ l·∫•y d·ªØ li·ªáu\\ndf = build_dataset(seed_urls)\\n\\n\\n# L∆∞u d·ªØ li·ªáu th√†nh file CSV\\ndf.to_csv('dataset3.csv', index=False)\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "seed_urls = [\n",
    "    'https://notes.ayushsharma.in/technology',\n",
    "    'https://www.ayush.nz/video-games'\n",
    "]\n",
    "\n",
    "def build_dataset(seed_urls):\n",
    "    news_data = []\n",
    "    for url in seed_urls:\n",
    "        news_category = url.split('/')[-1]\n",
    "        data = requests.get(url)\n",
    "        soup = BeautifulSoup(data.content, 'html.parser')\n",
    "        tables = soup.find_all('div',class_= 'col')\n",
    "        for id, i in enumerate(tables):\n",
    "            title = i.find_all('h5',class_='card-title')\n",
    "            excerpt = i.find_all('small', class_ = 'card-text')\n",
    "            pub_date = i.find_all('div', class_ = 'card-footer text-end')\n",
    "            if title and excerpt and pub_date:\n",
    "                title_position = title[0].text.strip()\n",
    "                excerpt_position = excerpt[0].text.strip()\n",
    "                date_published = pub_date[0].text.strip()\n",
    "                news_data.append([title_position, excerpt_position, date_published, news_category])\n",
    "        df = pd.DataFrame(news_data,columns=['title', 'excerpt', 'pub_date', 'category'])\n",
    "    return df\n",
    "\n",
    "# G·ªçi h√†m ƒë·ªÉ l·∫•y d·ªØ li·ªáu\n",
    "df = build_dataset(seed_urls)\n",
    "\n",
    "\n",
    "# L∆∞u d·ªØ li·ªáu th√†nh file CSV\n",
    "df.to_csv('dataset3.csv', index=False)\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = requests.get('https://notes.ayushsharma.in/technology',\n",
    "                   'https://www.ayush.nz/video-games')\n",
    "soup = BeautifulSoup(url.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<h5 class=\"card-title\">Consuming APIs responsibly</h5>, <h5 class=\"card-title\">Create a series of posts with navigation in Jekyll</h5>, <h5 class=\"card-title\">A practical guide to light and dark mode in Bootstrap 5 and Jekyll</h5>, <h5 class=\"card-title\">Nemo - The Ubuntu file manager you didn‚Äôt know you needed</h5>, <h5 class=\"card-title\">Announcing Fediverse.to!</h5>, <h5 class=\"card-title\">Easy pretty URL redirects with Jekyll and Netlify</h5>, <h5 class=\"card-title\">Linking Jekyll pages back to their Git source code</h5>, <h5 class=\"card-title\">Optimising JPG and PNG images for a Jekyll website</h5>, <h5 class=\"card-title\">Quick and easy client-side JavaScript search with Lunr.js</h5>, <h5 class=\"card-title\">Creating light and dark themes for websites the right way using prefers-color-scheme</h5>, <h5 class=\"card-title\">Make Linux apps for Notion, Mastodon, or any web app using Nativefier</h5>, <h5 class=\"card-title\">Inserting dynamic data into Jekyll static sites using Python or Bash</h5>, <h5 class=\"card-title\">Introduction to Ansible</h5>, <h5 class=\"card-title\">Introduction to YAML</h5>, <h5 class=\"card-title\">Introduction to Jekyll</h5>, <h5 class=\"card-title\">Multi-machine Setup and Configuration with Vagrant</h5>, <h5 class=\"card-title\">Provisioning with Vagrant</h5>, <h5 class=\"card-title\">Introduction to Vagrant</h5>, <h5 class=\"card-title\">A Guide to Web Scraping in Python using BeautifulSoup</h5>, <h5 class=\"card-title\">Using variables in Jekyll to define custom content</h5>, <h5 class=\"card-title\">The evolution of ayushsharma.in: Jekyll, Bootstrap, Netlify, static websites, and responsive design.</h5>, <h5 class=\"card-title\">5 key best practices for sane and usable Terraform setups</h5>, <h5 class=\"card-title\">Cloud Infrastructure SAST: Scanning Terraform for security vulnerabilities and non-compliance using Checkov</h5>, <h5 class=\"card-title\">Terraform + Helm: A match made in heaven/hell?</h5>, <h5 class=\"card-title\">Automating ArgoCD using ArgoCD!</h5>, <h5 class=\"card-title\">Getting started with ArgoCD</h5>, <h5 class=\"card-title\">Creating ready-to-use AWS Security Groups using Terraform Registry, Named Groups, and Named Rules</h5>, <h5 class=\"card-title\">Creating AWS VPCs in 2 minutes with Terraform Registry</h5>, <h5 class=\"card-title\">Continuous delivery on GitLab: Pushing Docker images to DockerHub using GitLab Pipelines</h5>, <h5 class=\"card-title\">Configuring Elasticsearch snapshots using SLM on Google Compute Engine</h5>, <h5 class=\"card-title\">‚Äã‚ÄãWorking From Home and Software Engineering</h5>, <h5 class=\"card-title\">‚Äã‚ÄãThe Virus ‚Äãüò∑‚Äã and the Cloud ‚Äã‚õÖ‚Äã: Tips on AWS cost-saving in these weird ‚Äãü§Ø‚Äã times</h5>, <h5 class=\"card-title\">Replicating Bitbucket Pipelines on your laptop for local debugging</h5>, <h5 class=\"card-title\">Cloning another Bitbucket repository in Bitbucket Pipelines</h5>, <h5 class=\"card-title\">Deploying git submodules in Bitbucket Pipelines</h5>, <h5 class=\"card-title\">Automating Amazon Elastic Container (ECR) container builds using Bitbucket Pipelines</h5>, <h5 class=\"card-title\">Taming AWS costs with Cost and Usage Reports + AWS Athena</h5>, <h5 class=\"card-title\">Exporting Bitucket repositories and Pipelines with Python</h5>, <h5 class=\"card-title\">Rediscovering Logo with Bob the turtle</h5>, <h5 class=\"card-title\">Automating Serverless framework deployments using Bitbucket Pipelines</h5>, <h5 class=\"card-title\">Automating AWS Lambda deployments using Bitbucket Pipelines and Bitbucket Pipes</h5>, <h5 class=\"card-title\">Algorithms in Python: Exchange Sorts</h5>, <h5 class=\"card-title\">The Three Ways of DevOps: Notes on The Phoenix Project</h5>, <h5 class=\"card-title\">Working with NumPy in Python</h5>, <h5 class=\"card-title\">Data Types in Python</h5>, <h5 class=\"card-title\">Dockerizing Tweet-Toot: A practical guide to deploying your app using Docker</h5>, <h5 class=\"card-title\">SublimeText 3 setup for Jekyll development</h5>, <h5 class=\"card-title\">Gartner's Magic Quadrants: A summary of cloud Infrastructure-as-a-Service providers over the last 5 years</h5>, <h5 class=\"card-title\">Tweet-Toot: Building a bot for Mastodon using Python</h5>, <h5 class=\"card-title\">Moving from CloudFlare to StackPath</h5>, <h5 class=\"card-title\">Understanding vendor lock-in and breaking the cycle</h5>, <h5 class=\"card-title\">Rolling clusters for deployment with Terraform</h5>, <h5 class=\"card-title\">Working with Terraform Modules</h5>, <h5 class=\"card-title\">Getting started with Terraform</h5>, <h5 class=\"card-title\">Upgrading to HTTP/2</h5>, <h5 class=\"card-title\">HTTP security headers: Referrer-Policy</h5>, <h5 class=\"card-title\">HTTP security headers: X-Content-Type-Options</h5>, <h5 class=\"card-title\">HTTP security headers: X-Frame-Options</h5>, <h5 class=\"card-title\">HTTP security headers: HTTP-Strict-Transport-Security</h5>, <h5 class=\"card-title\">HTTP security headers: X-XSS-Protection</h5>, <h5 class=\"card-title\">HTTP security headers: Content-Security-Policy</h5>, <h5 class=\"card-title\">I'm killing Disqus comments on my blog. Here's why.</h5>, <h5 class=\"card-title\">Posting messages to Slack using incoming webhooks and Python3 Requests API</h5>, <h5 class=\"card-title\">Using Packer and Ansible to create immutable servers, deploying code, and recycling instances</h5>, <h5 class=\"card-title\">Getting started with Packer</h5>, <h5 class=\"card-title\">The different ways I've deployed code over the years: the road to Immutable Servers</h5>, <h5 class=\"card-title\">Testing AWS Elastic Load Balancer health check endpoints with Python</h5>, <h5 class=\"card-title\">Complete Nginx Monitoring with Collectd and InfluxDB</h5>, <h5 class=\"card-title\">Deploying Jekyll blog automatically using Bitbucket Pipelines</h5>, <h5 class=\"card-title\">Migrating MySQL database tables to InfluxDB</h5>, <h5 class=\"card-title\">Backing up InfluxDB databases to S3</h5>, <h5 class=\"card-title\">Setting Up Grafana to use Collectd and InfluxDB</h5>, <h5 class=\"card-title\">Setting up Collectd and InfluxDB on Mac OS X</h5>, <h5 class=\"card-title\">Getting Started with time-series data using InfluxDB</h5>, <h5 class=\"card-title\">Getting started with server metrics collection with Collectd</h5>, <h5 class=\"card-title\">Retry Strategies for Transient Failures</h5>, <h5 class=\"card-title\">Using Route 53 as a Load Balancer</h5>, <h5 class=\"card-title\">MySQL Database backups to S3</h5>, <h5 class=\"card-title\">Mastodon Users and Instances in Sqlite3 Using Python</h5>, <h5 class=\"card-title\">The Ultimate Guide to Using Mail in Linux</h5>, <h5 class=\"card-title\">Fixing ValueError('unknown locale: %s' % localename) in Python</h5>, <h5 class=\"card-title\">Getting Started with Xinetd</h5>, <h5 class=\"card-title\">Getting City, Country and ISP of an IP address using Maxmind GeoIP</h5>, <h5 class=\"card-title\">AWS, GCS, Azure and Digital Ocean incidents by service in 2016</h5>, <h5 class=\"card-title\">I Have Something to Say II</h5>, <h5 class=\"card-title\">Using Weighted, Geo and Fail-over Routeing in Route 53</h5>, <h5 class=\"card-title\">You still might need a staging server in 2017</h5>, <h5 class=\"card-title\">AWS, GCS, Azure and Digital Ocean incidents in 2016</h5>, <h5 class=\"card-title\">I Have Something to Say</h5>, <h5 class=\"card-title\">Connecting VPCs in 2 AWS Regions (Site-to-site VPN)</h5>, <h5 class=\"card-title\">Installing PHP 7 FPM + MySQL 5.7 + Nginx 1.10 on Ubuntu 16.04</h5>, <h5 class=\"card-title\">Working with Logical Volume Manager (LVM)</h5>, <h5 class=\"card-title\">Fiddling with Logrotate</h5>, <h5 class=\"card-title\">AWS Route 53 Notes</h5>, <h5 class=\"card-title\">AWS EBS Types Read/Write Benchmarks</h5>, <h5 class=\"card-title\">Logging AWS spot instance termination</h5>, <h5 class=\"card-title\">Decompressing request using GZIP with Nginx</h5>, <h5 class=\"card-title\">Compressing output using GZIP with PHP 5.3</h5>, <h5 class=\"card-title\">Introduction to Load-balancing with Nginx</h5>, <h5 class=\"card-title\">Reading JWT token in Phalcon</h5>, <h5 class=\"card-title\">Setting Custom 404 Controller in Phalcon</h5>, <h5 class=\"card-title\">DNS Record Types</h5>, <h5 class=\"card-title\">Securing Nginx with Let's Encrypt Free SSL Certificate</h5>, <h5 class=\"card-title\">Vertical Scaling vs Horizontal Scaling</h5>, <h5 class=\"card-title\">Essential VIM Keyboard Shortcuts</h5>, <h5 class=\"card-title\">Notes on AWS SQS</h5>, <h5 class=\"card-title\">MySQL Physical Backup with Innobackupex</h5>, <h5 class=\"card-title\">Introduction to MySQL Partitioning</h5>, <h5 class=\"card-title\">Introduction to Fluentd</h5>, <h5 class=\"card-title\">NANO Keyboard Shortcuts</h5>, <h5 class=\"card-title\">JSON Web Tokens</h5>, <h5 class=\"card-title\">Hello @World</h5>]\n"
     ]
    }
   ],
   "source": [
    "title = soup.find_all('h5', {'class':'card-title'})\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<small class=\"card-text\">Or: Etiquette and table manners for pinging other people's servers.</small>, <small class=\"card-text\">Add Jekyll posts into a series with series navigation.</small>, <small class=\"card-text\">Implementing light and dark mode on your Bootstrap 5 + Jekyll website.</small>, <small class=\"card-text\">Celebrate 2022 with a shiny new file manager for Ubuntu!</small>, <small class=\"card-text\">I've been working on a search engine for Fediverse instances!</small>, <small class=\"card-text\">Combine Jekyll and Netlify to create pretty URL redirects as easy as 1-2-3.</small>, <small class=\"card-text\">Add a link back to the public Git hosting link for any static Jekyll blog.</small>, <small class=\"card-text\">Use CLI tools to generate resized and optimised thumbnails for articles header images.</small>, <small class=\"card-text\">Display search results from any JSON data object in the browser using Lunr.js.</small>, <small class=\"card-text\">Blur the line between desktop and web by letting the OS style your website or webapp.</small>, <small class=\"card-text\">Notion is an awesome life manager. And Mastodon is great for decentralised internet shenanigans. With Nativefier, I can now enjoy them as apps on Ubuntu 20.04.</small>, <small class=\"card-text\">Auto-generate Jekyll configuration files with content and avoid creating an API backend.</small>, <small class=\"card-text\">Ansible is the answer to custom scripts and tooling that eventually snowball into a kludge which breaks more things than it fixes.</small>, <small class=\"card-text\">What is YAML and why is it about time we started using it?</small>, <small class=\"card-text\">Jekyll is a framework for building websites - write your content in Markdown, use HTML/CSS for structure and presentation, and Jekyll compiles it all into static HTML. No servers. No backends. No fuss.</small>, <small class=\"card-text\">If you ever need to test an app and a database, did you know you can use Vagrant to bring up multiple testing machines at once? Here's how.</small>, <small class=\"card-text\">Ansible works well to provision a Vagrant box with everything installed from the get-go.</small>, <small class=\"card-text\">Vagrant helps you run other operating systems on your computer, meaning you can build things, test things, and do crazy shit without blowing up your own system.</small>, <small class=\"card-text\">Web-scraping is a useful but often neglected technical skill. The BeautifulSoup library in Python makes extracting HTML from web pages easy. Do with that what you will ;)</small>, <small class=\"card-text\">I recently discovered that Jekyll's config.yml can be used to define custom variables for reusing content. I feel like I've been living under a rock all this time. But to err over and over again is human.</small>, <small class=\"card-text\">In this article, I'll highlight some ideas for Jekyll collections, blog category pages, responsive web-design, and netlify.toml to make static website maintenance a breeze.</small>, <small class=\"card-text\">These are the top 5 lessons I've learned after 5 years of Terraform-ing.</small>, <small class=\"card-text\">In this article I explore Checkov, a static code analysis tool for Terraform.</small>, <small class=\"card-text\">I've just discovered that Terraform can deploy Helm Charts as well. But I'm not sure if I like it.</small>, <small class=\"card-text\">In this tutorial, I will show you how to automatically create multiple Applications in ArgoCD using ArgoCD!</small>, <small class=\"card-text\">In this post we meet ArgoCD: a simple pull-based GitOps deployment tool which syncs K8s manifest files with a cluster for easy and no-nonsense deployments.</small>, <small class=\"card-text\">Create parameterized AWS security groups quickly and consistently with Terraform Registry.</small>, <small class=\"card-text\">Create parameterized AWS VPCs quickly and consistently with Terraform Registry.</small>, <small class=\"card-text\">Build and push Docker images to DockerHub using GitLab's Pipelines feature.</small>, <small class=\"card-text\">A tutorial on how to configure automatic snapshots of Elasticsearch using the in-built Snapshot Lifecycle Manager on Google Compute Engine.</small>, <small class=\"card-text\">Your time and attention is your primary resource, so deploy it wisely.</small>, <small class=\"card-text\">2020 is the year startups are trying to save aggresively on cloud spend. I list down some key learnings based on my experience.</small>, <small class=\"card-text\">I love Bitbucket Pipelines, and debugging them on your laptop is even easier thanks to Docker containers. I'll show you how to debug Serverless deployments and diagnose broken builds.</small>, <small class=\"card-text\">I'll show you how to allow one Bitbucket repo to clone another during a Pipeline build.</small>, <small class=\"card-text\">Git submodules makes it easy have repos for common dependencies, but how to actually clone them in your Bitbucket Pipeline?</small>, <small class=\"card-text\">I'll show you how to build a Docker image in a Pipeline and push it to a container registry, in this case Amazon ECR.</small>, <small class=\"card-text\">AWS Cost &amp; Usage Reports with AWS Athena are vital for understanding cloud spend. I'll show you some handy Athena queries to break things down.</small>, <small class=\"card-text\">Bitbucket doesn't offer a dashboard yet, or an easy way to fetch information for all your repos and Pipelines. So I wrote a handy Python script for the job. It's great for configuring alerts or building near-real-time dashboards!</small>, <small class=\"card-text\">My very first programming language was Logo! I can still remember guiding that fuzzy little on-screen turtle to draw simple and complex shapes. So I found the Logo Python module and took a walk down memory lane.</small>, <small class=\"card-text\">The open-source Serverless framework makes it easy to build and deploy Lambda stacks. I'll walk you through deploying Serverless apps automatically using Pipelines.</small>, <small class=\"card-text\">Pipes is another great Continuous Delivery feature in Bitbucket: pre-built, ready-to-use, and parameterized deployment jobs.</small>, <small class=\"card-text\">Notes on implementing the basic Exchange sort algorithms in Python.</small>, <small class=\"card-text\">The Phoenix Project is one of the most approachable books for DevOps available today. Highly recommended, especially if you don't already know Conway's Law.</small>, <small class=\"card-text\">My Udacity Python Nanodegree introduced using NumPy to handle large arrays and datasets in Python. I put some notes togther for referencing later.</small>, <small class=\"card-text\">Some quick notes describing the basic data types in Python3 and their features.</small>, <small class=\"card-text\">Tweet-Toot is my personal project, a Twitter relay for the Mastodon social network. I recently dockerized the setup and put these notes together to explain the process.</small>, <small class=\"card-text\">SublimeText has some cool plugins for setting up a basic Jekyll development environment. Take a look.</small>, <small class=\"card-text\">Gartner's Magic Quadrants was one of the the first industry reports I read which covered where the cloud vendor's were headed and what their strengths and weaknesses were. I took some time to consolidate the Gartner findings over the last 5 years for comparison.</small>, <small class=\"card-text\">I joined the Mastodon social network in 2016 and felt a need for building a Twitter relay. We all left the birdsite for many reasons but not the people we met. So this project is a way to bring some of them over to Mastodon, in practice if not in spirit.</small>, <small class=\"card-text\">I love Cloudflare, but after facing some issues with TTFB I decided to move to StackPath, which proved to be a lot faster and feature-rich.</small>, <small class=\"card-text\">I went through one of Gartner's reports, and it says the key to breaking vendor lock-in is to commit fully to a single technology vendor, be it a cloud software provider, a social network, or our favorite sharing app. It seems controversial on the surface, but I wanted to jot down some quick notes. Maybe the approach is worth experimenting with?</small>, <small class=\"card-text\">Terraform enables more than infrastructure provisioning, you can even use it for deployments. Combine it with Packer, and you can have a very powerful immutable rolling deployment pipeline.</small>, <small class=\"card-text\">Terraform's Modules feature allows quickly building re-usable infrastructure templates to provision cloud environments repeatably. These notes will help set up a basic application for high-availability.</small>, <small class=\"card-text\">A basic walkthrough of Terraform, the open-source, cloud-agnostic IaC tool by HashiCorp, the makers of Vagrant.</small>, <small class=\"card-text\">It's about time we all move our web properties to HTTP/2. I list down some gotchas for those looking to migrate.</small>, <small class=\"card-text\">The web is a collection of inter-connected pages. This means chances are good that someone landing on your website is coming from another one, and when they leave your website, they take a lot of identifiable information with them. HTTP/2 allows you to control what happens to the referrer information when users leave your website.</small>, <small class=\"card-text\">HTTP/2 introduced a new feature which basically just turns off an old default feature: the browser's hankering for figuring out the content type of a resource. Why and how should we turn it off?</small>, <small class=\"card-text\">Inline-frames enable very basic phishing attacks. You can just include a bank's main website within your own website and lure the user to handover their passwords. HTTP2/ comes with built-in protection against this kind of threat.</small>, <small class=\"card-text\">HSTS is a security feature which prevents users from accessing your website over non-secure HTTP. It comes with HTTP/2, is easy to turn on, but very hard to turn off. Here's the why and how.</small>, <small class=\"card-text\">HTTP/2 comes with built-in protection for XSS. Here's what it does and how to turn it on.</small>, <small class=\"card-text\">HTTP/2's CSP let's you define a white-list of what's allowed and what's blocked on your website. This lets browsers block third-party trackers which try to annoy/harm your users. Here's the why and how.</small>, <small class=\"card-text\">I added the Disqus commenting platform to my blog some time ago. And then I found out that it was loading WAY TOO MANY tracking cookies inline and profiling my website users. This is how you build Orwellian software. And shitty software.</small>, <small class=\"card-text\">Slack has become a favorite of DevOps/SRE teams across the globe. It's a very easy-to-use and programmatic messaging platform. Here's the quick and easy process to posting messages to your Slack group from Python.</small>, <small class=\"card-text\">Packer is an amazing golden image builder. Ansible is a great deployment tool. So let's use them together!</small>, <small class=\"card-text\">Packer. Basically Docker for whole VMs. Another great tool by HashiCorp, this one modernises an old formula but retains the simplicity. Building immutable servers was never this easy.</small>, <small class=\"card-text\">I took a walk down memory lane to try and figure out how much my daily work has changed. The concepts are still the same, but the tools have become bigger, because our needs have shifted dramatically over the years.</small>, <small class=\"card-text\">A quick script for ad-hoc health-checking of load balancer instances.</small>, <small class=\"card-text\">I recently discovered InfluxDB as a great write-heavy database for storing metrics. These are my notes on monitoring the golden signals in Nginx using Collectd and InfluxDB.</small>, <small class=\"card-text\">Because why not? Here's how to build your Jekyll website and deploy it to a VM of your choice.</small>, <small class=\"card-text\">If you ever need to migrate a MySQL database to InfluxDB, say if you were using MySQL as a metrics database because you were too busy not knowing Influx even existed, then this handy Python script can do the job and take care of schema migrations too.</small>, <small class=\"card-text\">A handy bash script to backup your InfluxDB database to AWS S3; great for cron jobs.</small>, <small class=\"card-text\">Grafana provides out-of-the-box support for InfluxDB, so visualising the metrics you're collecting using Collectd, etc., is straightforward. Here's how to do it.</small>, <small class=\"card-text\">A quick copy-paste-able process for installing Collectd and InfluxDB on your Mac for some local testing.</small>, <small class=\"card-text\">A quick comparison of relational vs time-series databases, followed by a brief hands-on tutorial for InfluxDB on a local Mac OS.</small>, <small class=\"card-text\">Collectd, a C-based daemon, is a fast and lightweight metrics shipper.</small>, <small class=\"card-text\">A very basic reality of computer networking is that... it fails. And when it does, there are ways to retry your connections to make life easier for you and other clients as well.</small>, <small class=\"card-text\">AWS Elastic load balancers do their job well, but they can get pricey. So naturally I tried using Route53 for load balancing traffic. It was a lot harder than I thought, and while this experiment didn't succeed, I'm noting my approach here for better luck next time.</small>, <small class=\"card-text\">A handy bash script to backup all MySQL databases to AWS S3.</small>, <small class=\"card-text\">The title really says it all: exporting data from JSON and ingesting into Sqlite3.</small>, <small class=\"card-text\">I installed mutt to send email from the command-line. It's fast and the CLI switches are memorable. Worth a look if you use the CLI for sending emails a lot.</small>, <small class=\"card-text\">You get 3 guesses for what the solution could be...</small>, <small class=\"card-text\">Xinetd is a light-weight and straightfoward HTTP server. Not as powerful as Nginx, but it's great for simple things like configuring health checks.</small>, <small class=\"card-text\">The Maxmind GeoIP database is useful for looking up the country and ISP information for an IP address.</small>, <small class=\"card-text\">I pulled the data for technology incidents for the major cloud services. The findings were pretty interesting.</small>, <small class=\"card-text\">These have been the confessions of a firefighter who ignored the smoke.</small>, <small class=\"card-text\">At work, one of my recent projects involved setting up a multi-region failover with weighted-routing support. Thankfully, Route53 has all of these built-in. Here's how to do it.</small>, <small class=\"card-text\">It's 2017 and the cloud has matured by leaps and bounds. So do we still need staging servers?</small>, <small class=\"card-text\">I pulled the data for technology incidents on the major cloud platforms. The findings were pretty interesting.</small>, <small class=\"card-text\">Ten years from now, if or when I am in another job, no one is going to care whether I ran my production servers with my heart and soul. They will care if I saved money, they will care if I ran it efficiently, but you can do those things while still compromising your values.</small>, <small class=\"card-text\">A step-by-step guide for connecting 2 AWS VPSs using self-hosted StrongSwan VPNs.</small>, <small class=\"card-text\">These are instructions for installing PHP7, MySQL 5.7 and Nginx 1.10 on Ubuntu 16.04. Very copy-paste-able.</small>, <small class=\"card-text\">Some notes on Logical Volume Manager. What it is, why it is, and how to use it.</small>, <small class=\"card-text\">Logrotate is one of those built-in Linux things that we don't use often enough. Rotating logs, archiving them to S3, pushing them to some remote server/endpoint, etc. It's all doable with Logrotate.</small>, <small class=\"card-text\">Route53: what, why, how, why not.</small>, <small class=\"card-text\">I ran hdparm and dd on GP2, PIOPS, SC1, ST1, and Magnetic EBS volumes. Check out the results.</small>, <small class=\"card-text\">AWS spot instances provide 90% savings over on-demand servers. The downside? AWS can yank them whenever they want and you have 2 minutes to back things up. How do you know when the starting pistol fires?</small>, <small class=\"card-text\">If you're using a Lua module with Nginx, then decompressing GZIPped data requires some extra handling.</small>, <small class=\"card-text\">It's pretty hard to compress output with GZIP in PHP 5.3, but in case you ever need to, here's how.</small>, <small class=\"card-text\">I'll explore the basics of self-hosted load-balancing with Nginx using a convenient testing setup using Vagrant.</small>, <small class=\"card-text\">Here's how to read a response JSON web token in PHP Phalcon.</small>, <small class=\"card-text\">After CodeIgniter, Phalcon was the second PHP framework that I used. Blazingly fast and easy-to-use, one of the first things I did was create a custom 404 response controller.</small>, <small class=\"card-text\">A quick guide to the different DNS record types.</small>, <small class=\"card-text\">Let's Encrypt is the self-hosted, industry-standard method of generating SSL certificates for your applications. If you're still paying for SSL certificates you're doing it wrong.</small>, <small class=\"card-text\">The differences between vertical and horizontal scaling may be simple, but they're critical to using cloud technologies effectively.</small>, <small class=\"card-text\">A quick guide of essential VIM shortcuts.</small>, <small class=\"card-text\">AWS SQS: what, why, how, why not.</small>, <small class=\"card-text\">Innobackupex, part of Percona Xtrabackup, can perform physical backups of your MySQL databases.</small>, <small class=\"card-text\">MySQL partitioning basics: what, why, and how.</small>, <small class=\"card-text\">The legacy logging infrastructure we have to deal with today was designed for humans and not machines, so a lot of effort is wasted trying to make backend systems understand log data.</small>, <small class=\"card-text\">A quick reference of NANO shortcuts.</small>, <small class=\"card-text\">The following document assesses the possibility of using JWT (pronounced \"jot\") as a token exchange mechanism for APIs.</small>, <small class=\"card-text\">Hello, World, you little blue thing...</small>]\n"
     ]
    }
   ],
   "source": [
    "excerpt = soup.find_all('small', {'class':'card-text'})\n",
    "print(excerpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<div class=\"card-footer text-end\">\n",
      "<small>Nov 2022</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Feb 2022</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Jan 2022</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Jan 2022</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Jan 2022</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Nov 2021</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Nov 2021</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Nov 2021</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Nov 2021</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Oct 2021</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Oct 2021</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Oct 2021</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Aug 2021</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Aug 2021</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Aug 2021</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Aug 2021</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Aug 2021</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Aug 2021</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Aug 2021</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Aug 2021</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Jul 2021</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Jul 2021</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Jul 2021</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Jul 2021</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Jul 2021</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Jul 2021</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Sep 2020</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Sep 2020</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Jun 2020</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Jun 2020</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Jun 2020</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Apr 2020</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Mar 2020</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Feb 2020</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Feb 2020</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Aug 2019</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Aug 2019</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Jun 2019</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Jun 2019</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>May 2019</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>May 2019</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Mar 2019</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Jan 2019</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Oct 2018</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Sep 2018</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Sep 2018</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Sep 2018</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Sep 2018</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Sep 2018</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Jul 2018</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Jul 2018</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Jul 2018</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Jul 2018</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Oct 2017</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Sep 2017</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Sep 2017</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Sep 2017</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Sep 2017</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Sep 2017</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Sep 2017</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Sep 2017</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Sep 2017</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Sep 2017</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Sep 2017</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Sep 2017</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Sep 2017</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Sep 2017</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Aug 2017</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Aug 2017</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Aug 2017</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Aug 2017</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Aug 2017</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Aug 2017</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Aug 2017</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Aug 2017</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Aug 2017</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Aug 2017</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Aug 2017</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Apr 2017</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Apr 2017</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Mar 2017</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Mar 2017</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Mar 2017</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Mar 2017</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Mar 2017</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Mar 2017</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Mar 2017</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Mar 2017</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Mar 2017</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Feb 2017</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Feb 2017</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Feb 2017</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Jan 2017</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Jan 2017</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Jan 2017</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Oct 2016</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Oct 2016</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Oct 2016</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Aug 2016</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Aug 2016</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Aug 2016</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Aug 2016</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Aug 2016</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Aug 2016</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Aug 2016</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Aug 2016</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Aug 2016</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Aug 2016</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Aug 2016</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Aug 2016</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Aug 2016</small>\n",
      "</div>, <div class=\"card-footer text-end\">\n",
      "<small>Aug 2016</small>\n",
      "</div>]\n"
     ]
    }
   ],
   "source": [
    "pub_date = soup.find_all(class_= \"card-footer text-end\")\n",
    "print(pub_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Consuming APIs responsibly\n",
      "Excerpt: Or: Etiquette and table manners for pinging other people's servers.\n",
      "pub_date: \n",
      "Nov 2022\n",
      "\n",
      "\n",
      "Title: Create a series of posts with navigation in Jekyll\n",
      "Excerpt: Add Jekyll posts into a series with series navigation.\n",
      "pub_date: \n",
      "Feb 2022\n",
      "\n",
      "\n",
      "Title: A practical guide to light and dark mode in Bootstrap 5 and Jekyll\n",
      "Excerpt: Implementing light and dark mode on your Bootstrap 5 + Jekyll website.\n",
      "pub_date: \n",
      "Jan 2022\n",
      "\n",
      "\n",
      "Title: Nemo - The Ubuntu file manager you didn‚Äôt know you needed\n",
      "Excerpt: Celebrate 2022 with a shiny new file manager for Ubuntu!\n",
      "pub_date: \n",
      "Jan 2022\n",
      "\n",
      "\n",
      "Title: Announcing Fediverse.to!\n",
      "Excerpt: I've been working on a search engine for Fediverse instances!\n",
      "pub_date: \n",
      "Jan 2022\n",
      "\n",
      "\n",
      "Title: Easy pretty URL redirects with Jekyll and Netlify\n",
      "Excerpt: Combine Jekyll and Netlify to create pretty URL redirects as easy as 1-2-3.\n",
      "pub_date: \n",
      "Nov 2021\n",
      "\n",
      "\n",
      "Title: Linking Jekyll pages back to their Git source code\n",
      "Excerpt: Add a link back to the public Git hosting link for any static Jekyll blog.\n",
      "pub_date: \n",
      "Nov 2021\n",
      "\n",
      "\n",
      "Title: Optimising JPG and PNG images for a Jekyll website\n",
      "Excerpt: Use CLI tools to generate resized and optimised thumbnails for articles header images.\n",
      "pub_date: \n",
      "Nov 2021\n",
      "\n",
      "\n",
      "Title: Quick and easy client-side JavaScript search with Lunr.js\n",
      "Excerpt: Display search results from any JSON data object in the browser using Lunr.js.\n",
      "pub_date: \n",
      "Nov 2021\n",
      "\n",
      "\n",
      "Title: Creating light and dark themes for websites the right way using prefers-color-scheme\n",
      "Excerpt: Blur the line between desktop and web by letting the OS style your website or webapp.\n",
      "pub_date: \n",
      "Oct 2021\n",
      "\n",
      "\n",
      "Title: Make Linux apps for Notion, Mastodon, or any web app using Nativefier\n",
      "Excerpt: Notion is an awesome life manager. And Mastodon is great for decentralised internet shenanigans. With Nativefier, I can now enjoy them as apps on Ubuntu 20.04.\n",
      "pub_date: \n",
      "Oct 2021\n",
      "\n",
      "\n",
      "Title: Inserting dynamic data into Jekyll static sites using Python or Bash\n",
      "Excerpt: Auto-generate Jekyll configuration files with content and avoid creating an API backend.\n",
      "pub_date: \n",
      "Oct 2021\n",
      "\n",
      "\n",
      "Title: Introduction to Ansible\n",
      "Excerpt: Ansible is the answer to custom scripts and tooling that eventually snowball into a kludge which breaks more things than it fixes.\n",
      "pub_date: \n",
      "Aug 2021\n",
      "\n",
      "\n",
      "Title: Introduction to YAML\n",
      "Excerpt: What is YAML and why is it about time we started using it?\n",
      "pub_date: \n",
      "Aug 2021\n",
      "\n",
      "\n",
      "Title: Introduction to Jekyll\n",
      "Excerpt: Jekyll is a framework for building websites - write your content in Markdown, use HTML/CSS for structure and presentation, and Jekyll compiles it all into static HTML. No servers. No backends. No fuss.\n",
      "pub_date: \n",
      "Aug 2021\n",
      "\n",
      "\n",
      "Title: Multi-machine Setup and Configuration with Vagrant\n",
      "Excerpt: If you ever need to test an app and a database, did you know you can use Vagrant to bring up multiple testing machines at once? Here's how.\n",
      "pub_date: \n",
      "Aug 2021\n",
      "\n",
      "\n",
      "Title: Provisioning with Vagrant\n",
      "Excerpt: Ansible works well to provision a Vagrant box with everything installed from the get-go.\n",
      "pub_date: \n",
      "Aug 2021\n",
      "\n",
      "\n",
      "Title: Introduction to Vagrant\n",
      "Excerpt: Vagrant helps you run other operating systems on your computer, meaning you can build things, test things, and do crazy shit without blowing up your own system.\n",
      "pub_date: \n",
      "Aug 2021\n",
      "\n",
      "\n",
      "Title: A Guide to Web Scraping in Python using BeautifulSoup\n",
      "Excerpt: Web-scraping is a useful but often neglected technical skill. The BeautifulSoup library in Python makes extracting HTML from web pages easy. Do with that what you will ;)\n",
      "pub_date: \n",
      "Aug 2021\n",
      "\n",
      "\n",
      "Title: Using variables in Jekyll to define custom content\n",
      "Excerpt: I recently discovered that Jekyll's config.yml can be used to define custom variables for reusing content. I feel like I've been living under a rock all this time. But to err over and over again is human.\n",
      "pub_date: \n",
      "Aug 2021\n",
      "\n",
      "\n",
      "Title: The evolution of ayushsharma.in: Jekyll, Bootstrap, Netlify, static websites, and responsive design.\n",
      "Excerpt: In this article, I'll highlight some ideas for Jekyll collections, blog category pages, responsive web-design, and netlify.toml to make static website maintenance a breeze.\n",
      "pub_date: \n",
      "Jul 2021\n",
      "\n",
      "\n",
      "Title: 5 key best practices for sane and usable Terraform setups\n",
      "Excerpt: These are the top 5 lessons I've learned after 5 years of Terraform-ing.\n",
      "pub_date: \n",
      "Jul 2021\n",
      "\n",
      "\n",
      "Title: Cloud Infrastructure SAST: Scanning Terraform for security vulnerabilities and non-compliance using Checkov\n",
      "Excerpt: In this article I explore Checkov, a static code analysis tool for Terraform.\n",
      "pub_date: \n",
      "Jul 2021\n",
      "\n",
      "\n",
      "Title: Terraform + Helm: A match made in heaven/hell?\n",
      "Excerpt: I've just discovered that Terraform can deploy Helm Charts as well. But I'm not sure if I like it.\n",
      "pub_date: \n",
      "Jul 2021\n",
      "\n",
      "\n",
      "Title: Automating ArgoCD using ArgoCD!\n",
      "Excerpt: In this tutorial, I will show you how to automatically create multiple Applications in ArgoCD using ArgoCD!\n",
      "pub_date: \n",
      "Jul 2021\n",
      "\n",
      "\n",
      "Title: Getting started with ArgoCD\n",
      "Excerpt: In this post we meet ArgoCD: a simple pull-based GitOps deployment tool which syncs K8s manifest files with a cluster for easy and no-nonsense deployments.\n",
      "pub_date: \n",
      "Jul 2021\n",
      "\n",
      "\n",
      "Title: Creating ready-to-use AWS Security Groups using Terraform Registry, Named Groups, and Named Rules\n",
      "Excerpt: Create parameterized AWS security groups quickly and consistently with Terraform Registry.\n",
      "pub_date: \n",
      "Sep 2020\n",
      "\n",
      "\n",
      "Title: Creating AWS VPCs in 2 minutes with Terraform Registry\n",
      "Excerpt: Create parameterized AWS VPCs quickly and consistently with Terraform Registry.\n",
      "pub_date: \n",
      "Sep 2020\n",
      "\n",
      "\n",
      "Title: Continuous delivery on GitLab: Pushing Docker images to DockerHub using GitLab Pipelines\n",
      "Excerpt: Build and push Docker images to DockerHub using GitLab's Pipelines feature.\n",
      "pub_date: \n",
      "Jun 2020\n",
      "\n",
      "\n",
      "Title: Configuring Elasticsearch snapshots using SLM on Google Compute Engine\n",
      "Excerpt: A tutorial on how to configure automatic snapshots of Elasticsearch using the in-built Snapshot Lifecycle Manager on Google Compute Engine.\n",
      "pub_date: \n",
      "Jun 2020\n",
      "\n",
      "\n",
      "Title: ‚Äã‚ÄãWorking From Home and Software Engineering\n",
      "Excerpt: Your time and attention is your primary resource, so deploy it wisely.\n",
      "pub_date: \n",
      "Jun 2020\n",
      "\n",
      "\n",
      "Title: ‚Äã‚ÄãThe Virus ‚Äãüò∑‚Äã and the Cloud ‚Äã‚õÖ‚Äã: Tips on AWS cost-saving in these weird ‚Äãü§Ø‚Äã times\n",
      "Excerpt: 2020 is the year startups are trying to save aggresively on cloud spend. I list down some key learnings based on my experience.\n",
      "pub_date: \n",
      "Apr 2020\n",
      "\n",
      "\n",
      "Title: Replicating Bitbucket Pipelines on your laptop for local debugging\n",
      "Excerpt: I love Bitbucket Pipelines, and debugging them on your laptop is even easier thanks to Docker containers. I'll show you how to debug Serverless deployments and diagnose broken builds.\n",
      "pub_date: \n",
      "Mar 2020\n",
      "\n",
      "\n",
      "Title: Cloning another Bitbucket repository in Bitbucket Pipelines\n",
      "Excerpt: I'll show you how to allow one Bitbucket repo to clone another during a Pipeline build.\n",
      "pub_date: \n",
      "Feb 2020\n",
      "\n",
      "\n",
      "Title: Deploying git submodules in Bitbucket Pipelines\n",
      "Excerpt: Git submodules makes it easy have repos for common dependencies, but how to actually clone them in your Bitbucket Pipeline?\n",
      "pub_date: \n",
      "Feb 2020\n",
      "\n",
      "\n",
      "Title: Automating Amazon Elastic Container (ECR) container builds using Bitbucket Pipelines\n",
      "Excerpt: I'll show you how to build a Docker image in a Pipeline and push it to a container registry, in this case Amazon ECR.\n",
      "pub_date: \n",
      "Aug 2019\n",
      "\n",
      "\n",
      "Title: Taming AWS costs with Cost and Usage Reports + AWS Athena\n",
      "Excerpt: AWS Cost & Usage Reports with AWS Athena are vital for understanding cloud spend. I'll show you some handy Athena queries to break things down.\n",
      "pub_date: \n",
      "Aug 2019\n",
      "\n",
      "\n",
      "Title: Exporting Bitucket repositories and Pipelines with Python\n",
      "Excerpt: Bitbucket doesn't offer a dashboard yet, or an easy way to fetch information for all your repos and Pipelines. So I wrote a handy Python script for the job. It's great for configuring alerts or building near-real-time dashboards!\n",
      "pub_date: \n",
      "Jun 2019\n",
      "\n",
      "\n",
      "Title: Rediscovering Logo with Bob the turtle\n",
      "Excerpt: My very first programming language was Logo! I can still remember guiding that fuzzy little on-screen turtle to draw simple and complex shapes. So I found the Logo Python module and took a walk down memory lane.\n",
      "pub_date: \n",
      "Jun 2019\n",
      "\n",
      "\n",
      "Title: Automating Serverless framework deployments using Bitbucket Pipelines\n",
      "Excerpt: The open-source Serverless framework makes it easy to build and deploy Lambda stacks. I'll walk you through deploying Serverless apps automatically using Pipelines.\n",
      "pub_date: \n",
      "May 2019\n",
      "\n",
      "\n",
      "Title: Automating AWS Lambda deployments using Bitbucket Pipelines and Bitbucket Pipes\n",
      "Excerpt: Pipes is another great Continuous Delivery feature in Bitbucket: pre-built, ready-to-use, and parameterized deployment jobs.\n",
      "pub_date: \n",
      "May 2019\n",
      "\n",
      "\n",
      "Title: Algorithms in Python: Exchange Sorts\n",
      "Excerpt: Notes on implementing the basic Exchange sort algorithms in Python.\n",
      "pub_date: \n",
      "Mar 2019\n",
      "\n",
      "\n",
      "Title: The Three Ways of DevOps: Notes on The Phoenix Project\n",
      "Excerpt: The Phoenix Project is one of the most approachable books for DevOps available today. Highly recommended, especially if you don't already know Conway's Law.\n",
      "pub_date: \n",
      "Jan 2019\n",
      "\n",
      "\n",
      "Title: Working with NumPy in Python\n",
      "Excerpt: My Udacity Python Nanodegree introduced using NumPy to handle large arrays and datasets in Python. I put some notes togther for referencing later.\n",
      "pub_date: \n",
      "Oct 2018\n",
      "\n",
      "\n",
      "Title: Data Types in Python\n",
      "Excerpt: Some quick notes describing the basic data types in Python3 and their features.\n",
      "pub_date: \n",
      "Sep 2018\n",
      "\n",
      "\n",
      "Title: Dockerizing Tweet-Toot: A practical guide to deploying your app using Docker\n",
      "Excerpt: Tweet-Toot is my personal project, a Twitter relay for the Mastodon social network. I recently dockerized the setup and put these notes together to explain the process.\n",
      "pub_date: \n",
      "Sep 2018\n",
      "\n",
      "\n",
      "Title: SublimeText 3 setup for Jekyll development\n",
      "Excerpt: SublimeText has some cool plugins for setting up a basic Jekyll development environment. Take a look.\n",
      "pub_date: \n",
      "Sep 2018\n",
      "\n",
      "\n",
      "Title: Gartner's Magic Quadrants: A summary of cloud Infrastructure-as-a-Service providers over the last 5 years\n",
      "Excerpt: Gartner's Magic Quadrants was one of the the first industry reports I read which covered where the cloud vendor's were headed and what their strengths and weaknesses were. I took some time to consolidate the Gartner findings over the last 5 years for comparison.\n",
      "pub_date: \n",
      "Sep 2018\n",
      "\n",
      "\n",
      "Title: Tweet-Toot: Building a bot for Mastodon using Python\n",
      "Excerpt: I joined the Mastodon social network in 2016 and felt a need for building a Twitter relay. We all left the birdsite for many reasons but not the people we met. So this project is a way to bring some of them over to Mastodon, in practice if not in spirit.\n",
      "pub_date: \n",
      "Sep 2018\n",
      "\n",
      "\n",
      "Title: Moving from CloudFlare to StackPath\n",
      "Excerpt: I love Cloudflare, but after facing some issues with TTFB I decided to move to StackPath, which proved to be a lot faster and feature-rich.\n",
      "pub_date: \n",
      "Jul 2018\n",
      "\n",
      "\n",
      "Title: Understanding vendor lock-in and breaking the cycle\n",
      "Excerpt: I went through one of Gartner's reports, and it says the key to breaking vendor lock-in is to commit fully to a single technology vendor, be it a cloud software provider, a social network, or our favorite sharing app. It seems controversial on the surface, but I wanted to jot down some quick notes. Maybe the approach is worth experimenting with?\n",
      "pub_date: \n",
      "Jul 2018\n",
      "\n",
      "\n",
      "Title: Rolling clusters for deployment with Terraform\n",
      "Excerpt: Terraform enables more than infrastructure provisioning, you can even use it for deployments. Combine it with Packer, and you can have a very powerful immutable rolling deployment pipeline.\n",
      "pub_date: \n",
      "Jul 2018\n",
      "\n",
      "\n",
      "Title: Working with Terraform Modules\n",
      "Excerpt: Terraform's Modules feature allows quickly building re-usable infrastructure templates to provision cloud environments repeatably. These notes will help set up a basic application for high-availability.\n",
      "pub_date: \n",
      "Jul 2018\n",
      "\n",
      "\n",
      "Title: Getting started with Terraform\n",
      "Excerpt: A basic walkthrough of Terraform, the open-source, cloud-agnostic IaC tool by HashiCorp, the makers of Vagrant.\n",
      "pub_date: \n",
      "Oct 2017\n",
      "\n",
      "\n",
      "Title: Upgrading to HTTP/2\n",
      "Excerpt: It's about time we all move our web properties to HTTP/2. I list down some gotchas for those looking to migrate.\n",
      "pub_date: \n",
      "Sep 2017\n",
      "\n",
      "\n",
      "Title: HTTP security headers: Referrer-Policy\n",
      "Excerpt: The web is a collection of inter-connected pages. This means chances are good that someone landing on your website is coming from another one, and when they leave your website, they take a lot of identifiable information with them. HTTP/2 allows you to control what happens to the referrer information when users leave your website.\n",
      "pub_date: \n",
      "Sep 2017\n",
      "\n",
      "\n",
      "Title: HTTP security headers: X-Content-Type-Options\n",
      "Excerpt: HTTP/2 introduced a new feature which basically just turns off an old default feature: the browser's hankering for figuring out the content type of a resource. Why and how should we turn it off?\n",
      "pub_date: \n",
      "Sep 2017\n",
      "\n",
      "\n",
      "Title: HTTP security headers: X-Frame-Options\n",
      "Excerpt: Inline-frames enable very basic phishing attacks. You can just include a bank's main website within your own website and lure the user to handover their passwords. HTTP2/ comes with built-in protection against this kind of threat.\n",
      "pub_date: \n",
      "Sep 2017\n",
      "\n",
      "\n",
      "Title: HTTP security headers: HTTP-Strict-Transport-Security\n",
      "Excerpt: HSTS is a security feature which prevents users from accessing your website over non-secure HTTP. It comes with HTTP/2, is easy to turn on, but very hard to turn off. Here's the why and how.\n",
      "pub_date: \n",
      "Sep 2017\n",
      "\n",
      "\n",
      "Title: HTTP security headers: X-XSS-Protection\n",
      "Excerpt: HTTP/2 comes with built-in protection for XSS. Here's what it does and how to turn it on.\n",
      "pub_date: \n",
      "Sep 2017\n",
      "\n",
      "\n",
      "Title: HTTP security headers: Content-Security-Policy\n",
      "Excerpt: HTTP/2's CSP let's you define a white-list of what's allowed and what's blocked on your website. This lets browsers block third-party trackers which try to annoy/harm your users. Here's the why and how.\n",
      "pub_date: \n",
      "Sep 2017\n",
      "\n",
      "\n",
      "Title: I'm killing Disqus comments on my blog. Here's why.\n",
      "Excerpt: I added the Disqus commenting platform to my blog some time ago. And then I found out that it was loading WAY TOO MANY tracking cookies inline and profiling my website users. This is how you build Orwellian software. And shitty software.\n",
      "pub_date: \n",
      "Sep 2017\n",
      "\n",
      "\n",
      "Title: Posting messages to Slack using incoming webhooks and Python3 Requests API\n",
      "Excerpt: Slack has become a favorite of DevOps/SRE teams across the globe. It's a very easy-to-use and programmatic messaging platform. Here's the quick and easy process to posting messages to your Slack group from Python.\n",
      "pub_date: \n",
      "Sep 2017\n",
      "\n",
      "\n",
      "Title: Using Packer and Ansible to create immutable servers, deploying code, and recycling instances\n",
      "Excerpt: Packer is an amazing golden image builder. Ansible is a great deployment tool. So let's use them together!\n",
      "pub_date: \n",
      "Sep 2017\n",
      "\n",
      "\n",
      "Title: Getting started with Packer\n",
      "Excerpt: Packer. Basically Docker for whole VMs. Another great tool by HashiCorp, this one modernises an old formula but retains the simplicity. Building immutable servers was never this easy.\n",
      "pub_date: \n",
      "Sep 2017\n",
      "\n",
      "\n",
      "Title: The different ways I've deployed code over the years: the road to Immutable Servers\n",
      "Excerpt: I took a walk down memory lane to try and figure out how much my daily work has changed. The concepts are still the same, but the tools have become bigger, because our needs have shifted dramatically over the years.\n",
      "pub_date: \n",
      "Sep 2017\n",
      "\n",
      "\n",
      "Title: Testing AWS Elastic Load Balancer health check endpoints with Python\n",
      "Excerpt: A quick script for ad-hoc health-checking of load balancer instances.\n",
      "pub_date: \n",
      "Sep 2017\n",
      "\n",
      "\n",
      "Title: Complete Nginx Monitoring with Collectd and InfluxDB\n",
      "Excerpt: I recently discovered InfluxDB as a great write-heavy database for storing metrics. These are my notes on monitoring the golden signals in Nginx using Collectd and InfluxDB.\n",
      "pub_date: \n",
      "Aug 2017\n",
      "\n",
      "\n",
      "Title: Deploying Jekyll blog automatically using Bitbucket Pipelines\n",
      "Excerpt: Because why not? Here's how to build your Jekyll website and deploy it to a VM of your choice.\n",
      "pub_date: \n",
      "Aug 2017\n",
      "\n",
      "\n",
      "Title: Migrating MySQL database tables to InfluxDB\n",
      "Excerpt: If you ever need to migrate a MySQL database to InfluxDB, say if you were using MySQL as a metrics database because you were too busy not knowing Influx even existed, then this handy Python script can do the job and take care of schema migrations too.\n",
      "pub_date: \n",
      "Aug 2017\n",
      "\n",
      "\n",
      "Title: Backing up InfluxDB databases to S3\n",
      "Excerpt: A handy bash script to backup your InfluxDB database to AWS S3; great for cron jobs.\n",
      "pub_date: \n",
      "Aug 2017\n",
      "\n",
      "\n",
      "Title: Setting Up Grafana to use Collectd and InfluxDB\n",
      "Excerpt: Grafana provides out-of-the-box support for InfluxDB, so visualising the metrics you're collecting using Collectd, etc., is straightforward. Here's how to do it.\n",
      "pub_date: \n",
      "Aug 2017\n",
      "\n",
      "\n",
      "Title: Setting up Collectd and InfluxDB on Mac OS X\n",
      "Excerpt: A quick copy-paste-able process for installing Collectd and InfluxDB on your Mac for some local testing.\n",
      "pub_date: \n",
      "Aug 2017\n",
      "\n",
      "\n",
      "Title: Getting Started with time-series data using InfluxDB\n",
      "Excerpt: A quick comparison of relational vs time-series databases, followed by a brief hands-on tutorial for InfluxDB on a local Mac OS.\n",
      "pub_date: \n",
      "Aug 2017\n",
      "\n",
      "\n",
      "Title: Getting started with server metrics collection with Collectd\n",
      "Excerpt: Collectd, a C-based daemon, is a fast and lightweight metrics shipper.\n",
      "pub_date: \n",
      "Aug 2017\n",
      "\n",
      "\n",
      "Title: Retry Strategies for Transient Failures\n",
      "Excerpt: A very basic reality of computer networking is that... it fails. And when it does, there are ways to retry your connections to make life easier for you and other clients as well.\n",
      "pub_date: \n",
      "Aug 2017\n",
      "\n",
      "\n",
      "Title: Using Route 53 as a Load Balancer\n",
      "Excerpt: AWS Elastic load balancers do their job well, but they can get pricey. So naturally I tried using Route53 for load balancing traffic. It was a lot harder than I thought, and while this experiment didn't succeed, I'm noting my approach here for better luck next time.\n",
      "pub_date: \n",
      "Aug 2017\n",
      "\n",
      "\n",
      "Title: MySQL Database backups to S3\n",
      "Excerpt: A handy bash script to backup all MySQL databases to AWS S3.\n",
      "pub_date: \n",
      "Aug 2017\n",
      "\n",
      "\n",
      "Title: Mastodon Users and Instances in Sqlite3 Using Python\n",
      "Excerpt: The title really says it all: exporting data from JSON and ingesting into Sqlite3.\n",
      "pub_date: \n",
      "Apr 2017\n",
      "\n",
      "\n",
      "Title: The Ultimate Guide to Using Mail in Linux\n",
      "Excerpt: I installed mutt to send email from the command-line. It's fast and the CLI switches are memorable. Worth a look if you use the CLI for sending emails a lot.\n",
      "pub_date: \n",
      "Apr 2017\n",
      "\n",
      "\n",
      "Title: Fixing ValueError('unknown locale: %s' % localename) in Python\n",
      "Excerpt: You get 3 guesses for what the solution could be...\n",
      "pub_date: \n",
      "Mar 2017\n",
      "\n",
      "\n",
      "Title: Getting Started with Xinetd\n",
      "Excerpt: Xinetd is a light-weight and straightfoward HTTP server. Not as powerful as Nginx, but it's great for simple things like configuring health checks.\n",
      "pub_date: \n",
      "Mar 2017\n",
      "\n",
      "\n",
      "Title: Getting City, Country and ISP of an IP address using Maxmind GeoIP\n",
      "Excerpt: The Maxmind GeoIP database is useful for looking up the country and ISP information for an IP address.\n",
      "pub_date: \n",
      "Mar 2017\n",
      "\n",
      "\n",
      "Title: AWS, GCS, Azure and Digital Ocean incidents by service in 2016\n",
      "Excerpt: I pulled the data for technology incidents for the major cloud services. The findings were pretty interesting.\n",
      "pub_date: \n",
      "Mar 2017\n",
      "\n",
      "\n",
      "Title: I Have Something to Say II\n",
      "Excerpt: These have been the confessions of a firefighter who ignored the smoke.\n",
      "pub_date: \n",
      "Mar 2017\n",
      "\n",
      "\n",
      "Title: Using Weighted, Geo and Fail-over Routeing in Route 53\n",
      "Excerpt: At work, one of my recent projects involved setting up a multi-region failover with weighted-routing support. Thankfully, Route53 has all of these built-in. Here's how to do it.\n",
      "pub_date: \n",
      "Mar 2017\n",
      "\n",
      "\n",
      "Title: You still might need a staging server in 2017\n",
      "Excerpt: It's 2017 and the cloud has matured by leaps and bounds. So do we still need staging servers?\n",
      "pub_date: \n",
      "Mar 2017\n",
      "\n",
      "\n",
      "Title: AWS, GCS, Azure and Digital Ocean incidents in 2016\n",
      "Excerpt: I pulled the data for technology incidents on the major cloud platforms. The findings were pretty interesting.\n",
      "pub_date: \n",
      "Mar 2017\n",
      "\n",
      "\n",
      "Title: I Have Something to Say\n",
      "Excerpt: Ten years from now, if or when I am in another job, no one is going to care whether I ran my production servers with my heart and soul. They will care if I saved money, they will care if I ran it efficiently, but you can do those things while still compromising your values.\n",
      "pub_date: \n",
      "Mar 2017\n",
      "\n",
      "\n",
      "Title: Connecting VPCs in 2 AWS Regions (Site-to-site VPN)\n",
      "Excerpt: A step-by-step guide for connecting 2 AWS VPSs using self-hosted StrongSwan VPNs.\n",
      "pub_date: \n",
      "Feb 2017\n",
      "\n",
      "\n",
      "Title: Installing PHP 7 FPM + MySQL 5.7 + Nginx 1.10 on Ubuntu 16.04\n",
      "Excerpt: These are instructions for installing PHP7, MySQL 5.7 and Nginx 1.10 on Ubuntu 16.04. Very copy-paste-able.\n",
      "pub_date: \n",
      "Feb 2017\n",
      "\n",
      "\n",
      "Title: Working with Logical Volume Manager (LVM)\n",
      "Excerpt: Some notes on Logical Volume Manager. What it is, why it is, and how to use it.\n",
      "pub_date: \n",
      "Feb 2017\n",
      "\n",
      "\n",
      "Title: Fiddling with Logrotate\n",
      "Excerpt: Logrotate is one of those built-in Linux things that we don't use often enough. Rotating logs, archiving them to S3, pushing them to some remote server/endpoint, etc. It's all doable with Logrotate.\n",
      "pub_date: \n",
      "Jan 2017\n",
      "\n",
      "\n",
      "Title: AWS Route 53 Notes\n",
      "Excerpt: Route53: what, why, how, why not.\n",
      "pub_date: \n",
      "Jan 2017\n",
      "\n",
      "\n",
      "Title: AWS EBS Types Read/Write Benchmarks\n",
      "Excerpt: I ran hdparm and dd on GP2, PIOPS, SC1, ST1, and Magnetic EBS volumes. Check out the results.\n",
      "pub_date: \n",
      "Jan 2017\n",
      "\n",
      "\n",
      "Title: Logging AWS spot instance termination\n",
      "Excerpt: AWS spot instances provide 90% savings over on-demand servers. The downside? AWS can yank them whenever they want and you have 2 minutes to back things up. How do you know when the starting pistol fires?\n",
      "pub_date: \n",
      "Oct 2016\n",
      "\n",
      "\n",
      "Title: Decompressing request using GZIP with Nginx\n",
      "Excerpt: If you're using a Lua module with Nginx, then decompressing GZIPped data requires some extra handling.\n",
      "pub_date: \n",
      "Oct 2016\n",
      "\n",
      "\n",
      "Title: Compressing output using GZIP with PHP 5.3\n",
      "Excerpt: It's pretty hard to compress output with GZIP in PHP 5.3, but in case you ever need to, here's how.\n",
      "pub_date: \n",
      "Oct 2016\n",
      "\n",
      "\n",
      "Title: Introduction to Load-balancing with Nginx\n",
      "Excerpt: I'll explore the basics of self-hosted load-balancing with Nginx using a convenient testing setup using Vagrant.\n",
      "pub_date: \n",
      "Aug 2016\n",
      "\n",
      "\n",
      "Title: Reading JWT token in Phalcon\n",
      "Excerpt: Here's how to read a response JSON web token in PHP Phalcon.\n",
      "pub_date: \n",
      "Aug 2016\n",
      "\n",
      "\n",
      "Title: Setting Custom 404 Controller in Phalcon\n",
      "Excerpt: After CodeIgniter, Phalcon was the second PHP framework that I used. Blazingly fast and easy-to-use, one of the first things I did was create a custom 404 response controller.\n",
      "pub_date: \n",
      "Aug 2016\n",
      "\n",
      "\n",
      "Title: DNS Record Types\n",
      "Excerpt: A quick guide to the different DNS record types.\n",
      "pub_date: \n",
      "Aug 2016\n",
      "\n",
      "\n",
      "Title: Securing Nginx with Let's Encrypt Free SSL Certificate\n",
      "Excerpt: Let's Encrypt is the self-hosted, industry-standard method of generating SSL certificates for your applications. If you're still paying for SSL certificates you're doing it wrong.\n",
      "pub_date: \n",
      "Aug 2016\n",
      "\n",
      "\n",
      "Title: Vertical Scaling vs Horizontal Scaling\n",
      "Excerpt: The differences between vertical and horizontal scaling may be simple, but they're critical to using cloud technologies effectively.\n",
      "pub_date: \n",
      "Aug 2016\n",
      "\n",
      "\n",
      "Title: Essential VIM Keyboard Shortcuts\n",
      "Excerpt: A quick guide of essential VIM shortcuts.\n",
      "pub_date: \n",
      "Aug 2016\n",
      "\n",
      "\n",
      "Title: Notes on AWS SQS\n",
      "Excerpt: AWS SQS: what, why, how, why not.\n",
      "pub_date: \n",
      "Aug 2016\n",
      "\n",
      "\n",
      "Title: MySQL Physical Backup with Innobackupex\n",
      "Excerpt: Innobackupex, part of Percona Xtrabackup, can perform physical backups of your MySQL databases.\n",
      "pub_date: \n",
      "Aug 2016\n",
      "\n",
      "\n",
      "Title: Introduction to MySQL Partitioning\n",
      "Excerpt: MySQL partitioning basics: what, why, and how.\n",
      "pub_date: \n",
      "Aug 2016\n",
      "\n",
      "\n",
      "Title: Introduction to Fluentd\n",
      "Excerpt: The legacy logging infrastructure we have to deal with today was designed for humans and not machines, so a lot of effort is wasted trying to make backend systems understand log data.\n",
      "pub_date: \n",
      "Aug 2016\n",
      "\n",
      "\n",
      "Title: NANO Keyboard Shortcuts\n",
      "Excerpt: A quick reference of NANO shortcuts.\n",
      "pub_date: \n",
      "Aug 2016\n",
      "\n",
      "\n",
      "Title: JSON Web Tokens\n",
      "Excerpt: The following document assesses the possibility of using JWT (pronounced \"jot\") as a token exchange mechanism for APIs.\n",
      "pub_date: \n",
      "Aug 2016\n",
      "\n",
      "\n",
      "Title: Hello @World\n",
      "Excerpt: Hello, World, you little blue thing...\n",
      "pub_date: \n",
      "Aug 2016\n",
      "\n",
      "\n",
      "Title: Rise of the Argonauts review\n",
      "Excerpt: Stunning level design, innovative combat system, and beautiful character models make this game worth your time and money.\n",
      "pub_date: \n",
      "Jun 2009\n",
      "\n",
      "\n",
      "Title: A guide to better town management in Caesar III\n",
      "Excerpt: Caesar III can be challenging, even more so if your town is not productive.\n",
      "pub_date: \n",
      "Jul 2005\n",
      "\n",
      "\n",
      "Title: Metal Fatigue review\n",
      "Excerpt: A review of Metal Fatigue, the last great Mech game with land-based, underground, and orbital combat!\n",
      "pub_date: \n",
      "Jul 2005\n",
      "\n",
      "\n",
      "Title: Command and Conquer: Red Alert 2 review\n",
      "Excerpt: A review of Command and Conquer: Red Alert 2, one of the best RTS games of all time.\n",
      "pub_date: \n",
      "Jul 2005\n",
      "\n",
      "\n",
      "Title: Top 10 tips for Command and Conquer: Red Alert 2!\n",
      "Excerpt: Having trouble with Command and Conquer: Red Alert 2? Here are a few basic beginner things you should remember while playing.\n",
      "pub_date: \n",
      "Jun 2005\n",
      "\n",
      "\n",
      "Title: Command and Conquer: Red Alert 2 - Red Revolution walkthrough\n",
      "Excerpt: A walkthrough of Command and Conquer: Red Alert 2's penultimate mission Red Revolution.\n",
      "pub_date: \n",
      "Jun 2005\n",
      "\n",
      "\n",
      "Title: Black and White tips and editing the game\n",
      "Excerpt: A few handy tips for the game, and a brief tutorial on how to edit the game.\n",
      "pub_date: \n",
      "Jun 2005\n",
      "\n",
      "\n",
      "Title: Command and Conquer: Red Alert 2 - Chronostorm walkthrough\n",
      "Excerpt: A walkthrough of Command and Conquer: Red Alert 2's final Allied mission Chronostorm.\n",
      "pub_date: \n",
      "Jun 2005\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# T·∫°o danh s√°ch tr·ªëng ƒë·ªÉ ch·ª©a d·ªØ li·ªáu\n",
    "data = []\n",
    "\n",
    "# L·∫∑p qua c√°c URL v√† l·∫•y d·ªØ li·ªáu t·ª´ m·ªói URL\n",
    "for url in seed_urls:\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # L·∫•y d·ªØ li·ªáu t·ª´ trang web\n",
    "    titles = soup.find_all('h5', {'class': 'card-title'})\n",
    "    excerpts = soup.find_all('small', {'class': 'card-text'})\n",
    "    pub_dates = soup.find_all(class_='card-footer text-end')\n",
    "    \n",
    "    # Th√™m d·ªØ li·ªáu v√†o danh s√°ch data\n",
    "    \"\"\"titles: ƒê√¢y l√† danh s√°ch (list) ch·ª©a c√°c ph·∫ßn t·ª≠. Trong tr∆∞·ªùng h·ª£p c·ªßa b·∫°n, danh s√°ch n√†y ch·ª©a c√°c th·∫ª HTML <h5> ch·ª©a c√°c ti√™u ƒë·ªÅ b√†i vi·∫øt t·ª´ trang web.\n",
    "    for title in titles: ƒê√¢y l√† m·ªôt v√≤ng l·∫∑p for d√πng ƒë·ªÉ duy·ªát qua t·ª´ng ph·∫ßn t·ª≠ trong danh s√°ch titles. Trong m·ªói l·∫ßn l·∫∑p, bi·∫øn title s·∫Ω tr·ªè ƒë·∫øn m·ªôt ph·∫ßn t·ª≠ trong danh s√°ch titles.\n",
    "    title.text: ·ªû b√™n trong v√≤ng l·∫∑p for, ch√∫ng ta s·ª≠ d·ª•ng title (bi·∫øn ƒë∆∞·ª£c ƒë·∫∑t trong v√≤ng l·∫∑p) ƒë·ªÉ truy c·∫≠p v√†o n·ªôi dung vƒÉn b·∫£n b√™n trong th·∫ª <h5>. C·ª• th·ªÉ, .text l√† thu·ªôc t√≠nh ƒë·ªÉ truy c·∫≠p v√†o vƒÉn b·∫£n b√™n trong th·∫ª.\n",
    "    title.text for title in titles: To√†n b·ªô bi·ªÉu th·ª©c generator comprehension n√†y t·∫°o ra m·ªôt danh s√°ch m·ªõi, trong ƒë√≥ m·ªói ph·∫ßn t·ª≠ c·ªßa danh s√°ch m·ªõi ch·ª©a vƒÉn b·∫£n t·ª´ m·ªôt th·∫ª <h5> trong danh s√°ch titles.\"\"\"\n",
    "    data.append({\n",
    "        'titles': [title.text for title in titles],\n",
    "        'excerpts': [excerpt.text for excerpt in excerpts],\n",
    "        'pub_dates': [date.text for date in pub_dates]\n",
    "    })\n",
    "\n",
    "# In d·ªØ li·ªáu\n",
    "for item in data:\n",
    "    for i in range(len(item['titles'])):\n",
    "        print(f\"Title: {item['titles'][i]}\")\n",
    "        print(f\"Excerpt: {item['excerpts'][i]}\")\n",
    "        print(f\"pub_date: {item['pub_dates'][i]}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c ghi v√†o file CSV: dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# Ghi d·ªØ li·ªáu v√†o file CSV\n",
    "csv_file_path = 'dataset.csv'\n",
    "\n",
    "with open(csv_file_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    fieldnames = ['Title', 'Excerpt', 'Pub_Date']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    # Vi·∫øt header\n",
    "    writer.writeheader()\n",
    "\n",
    "    # Vi·∫øt d·ªØ li·ªáu\n",
    "    for item in data:\n",
    "        for i in range(len(item['titles'])):\n",
    "            writer.writerow({\n",
    "                'Title': item['titles'][i],\n",
    "                'Excerpt': item['excerpts'][i],\n",
    "                'Pub_Date': item['pub_dates'][i]\n",
    "            })\n",
    "\n",
    "print(f\"D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c ghi v√†o file CSV: {csv_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω v√† ghi v√†o file CSV m·ªõi: dataset1\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "\n",
    "# ƒê·ªãnh nghƒ©a h√†m ƒë·ªÉ lo·∫°i b·ªè k√Ω t·ª± ƒë·∫∑c bi·ªát v√† ch·ªâ l·∫•y ng√†y th√°ng\n",
    "def loai_bo_ky_tu_dac_biet_va_lay_ngay_thang(text):\n",
    "    # S·ª≠ d·ª•ng bi·ªÉu th·ª©c ch√≠nh quy ƒë·ªÉ t√¨m v√† l·∫•y ng√†y th√°ng (ƒë·ªãnh d·∫°ng MM/YYYY)\n",
    "    match = re.search(r'\\w+\\s+(\\d{4})', text)\n",
    "    if match:\n",
    "        return match.group(0)\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "# ƒê·ªçc d·ªØ li·ªáu t·ª´ t·ªáp CSV\n",
    "data = []\n",
    "with open('dataset.csv', 'r', newline='', encoding='utf-8') as csvfile:\n",
    "    csv_reader = csv.DictReader(csvfile)\n",
    "\n",
    "    for row in csv_reader:\n",
    "        # Lo·∫°i b·ªè k√Ω t·ª± ƒë·∫∑c bi·ªát v√† ch·ªâ l·∫•y ng√†y th√°ng\n",
    "        row['Pub_Date'] = loai_bo_ky_tu_dac_biet_va_lay_ngay_thang(row['Pub_Date'])\n",
    "        data.append(row)\n",
    "\n",
    "# Ghi d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω v√†o m·ªôt t·ªáp CSV m·ªõi\n",
    "with open('dataset1.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    fieldnames = ['Title', 'Excerpt', 'Pub_Date']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(data)\n",
    "\n",
    "print(\"D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω v√† ghi v√†o file CSV m·ªõi: \" + \"dataset1\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3)  Lo·∫°i b·ªè k√Ω t·ª± c√≥ d·∫•u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \n",
    "H√†m remove_diacritics trong tr∆∞·ªùng h·ª£p n√†y ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ lo·∫°i b·ªè c√°c d·∫•u (k√Ω t·ª± c√≥ d·∫•u) trong vƒÉn b·∫£n. Th∆∞·ªùng th√¨ c√°c ng√¥n ng·ªØ s·ª≠ d·ª•ng d·∫•u ƒë·ªÉ bi·ªÉu th·ªã √¢m ƒëi·ªáu, ng·ªØ ƒëi·ªáu, v√† nhi·ªÅu ng·ªØ nghƒ©a kh√°c, nh∆∞ng trong m·ªôt s·ªë tr∆∞·ªùng h·ª£p, b·∫°n c√≥ th·ªÉ mu·ªën lo·∫°i b·ªè d·∫•u ƒë·ªÉ ƒë∆°n gi·∫£n h√≥a vƒÉn b·∫£n ho·∫∑c ƒë·ªÉ chu·∫©n h√≥a d·ªØ li·ªáu.\n",
    "H√†m remove_diacritics th∆∞·ªùng s·ª≠ d·ª•ng th∆∞ vi·ªán ho·∫∑c module nh∆∞ unidecode ƒë·ªÉ th·ª±c hi·ªán vi·ªác lo·∫°i b·ªè d·∫•u. ƒê√¢y l√† c√°ch n√≥ ho·∫°t ƒë·ªông:\n",
    "\n",
    "ƒê·∫ßu v√†o c·ªßa h√†m remove_diacritics l√† m·ªôt chu·ªói vƒÉn b·∫£n c√≥ ch·ª©a c√°c k√Ω t·ª± c√≥ d·∫•u, ch·∫≥ng h·∫°n nh∆∞ \"M√¨nh y√™u Vi·ªát Nam!\".\n",
    "\n",
    "H√†m n√†y s·∫Ω s·ª≠ d·ª•ng unidecode (ho·∫∑c t∆∞∆°ng t·ª±) ƒë·ªÉ chuy·ªÉn chu·ªói c√≥ d·∫•u th√†nh phi√™n b·∫£n kh√¥ng d·∫•u. Trong tr∆∞·ªùng h·ª£p v√≠ d·ª• tr√™n, n√≥ c√≥ th·ªÉ tr·ªü th√†nh \"Minh yeu Viet Nam!\".\n",
    "\n",
    "K·∫øt qu·∫£ c·ªßa h√†m remove_diacritics l√† chu·ªói vƒÉn b·∫£n kh√¥ng c√≥ c√°c k√Ω t·ª± c√≥ d·∫•u. ƒêi·ªÅu n√†y c√≥ th·ªÉ h·ªØu √≠ch khi b·∫°n mu·ªën x·ª≠ l√Ω d·ªØ li·ªáu ho·∫∑c t√¨m ki·∫øm trong vƒÉn b·∫£n m√† kh√¥ng quan tr·ªçng ƒë·∫øn vi·ªác c√≥ d·∫•u ho·∫∑c kh√¥ng d·∫•u."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω v√† l∆∞u v√†o t·ªáp dataset3.csv.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from unidecode import unidecode\n",
    "\n",
    "# ƒê·ªãnh nghƒ©a h√†m ƒë·ªÉ lo·∫°i b·ªè k√Ω t·ª± c√≥ d·∫•u t·ª´ m·ªôt chu·ªói\n",
    "def remove_diacritics(text):\n",
    "    return unidecode(text)\n",
    "\n",
    "# ƒê∆∞·ªùng d·∫´n ƒë·∫øn t·ªáp CSV ngu·ªìn\n",
    "input_csv_file = 'dataset1.csv'\n",
    "\n",
    "# ƒê∆∞·ªùng d·∫´n ƒë·∫øn t·ªáp CSV ƒë√≠ch\n",
    "output_csv_file = 'dataset3.csv'\n",
    "\n",
    "# M·ªü t·ªáp ngu·ªìn ƒë·ªÉ ƒë·ªçc\n",
    "with open(input_csv_file, mode='r', newline='') as input_file:\n",
    "    reader = csv.reader(input_file)\n",
    "    \n",
    "    # ƒê·ªçc d√≤ng ti√™u ƒë·ªÅ\n",
    "    header = next(reader)\n",
    "    \n",
    "    # M·ªü t·ªáp ƒë√≠ch ƒë·ªÉ ghi\n",
    "    with open(output_csv_file, mode='w', newline='') as output_file:\n",
    "        writer = csv.writer(output_file)\n",
    "        \n",
    "        # Ghi d√≤ng ti√™u ƒë·ªÅ\n",
    "        writer.writerow(header)\n",
    "\n",
    "        # Duy·ªát qua t·ª´ng d√≤ng d·ªØ li·ªáu trong t·ªáp ngu·ªìn\n",
    "        for row in reader:\n",
    "            # Lo·∫°i b·ªè k√Ω t·ª± c√≥ d·∫•u t·ª´ t·∫•t c·∫£ c√°c c·ªôt\n",
    "            cleaned_row = [remove_diacritics(cell) for cell in row]\n",
    "    \n",
    "            # Ghi d·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω v√†o t·ªáp ƒë√≠ch\n",
    "            writer.writerow(cleaned_row)\n",
    "\n",
    "\n",
    "print(\"D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω v√† l∆∞u v√†o t·ªáp dataset3.csv.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4)  Expand contractions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \n",
    "H√†m mo_rong_tu_viet_tat trong tr∆∞·ªùng h·ª£p n√†y d∆∞·ªùng nh∆∞ l√† m·ªôt h√†m ƒë·ªÉ m·ªü r·ªông c√°c t·ª´ vi·∫øt t·∫Øt trong vƒÉn b·∫£n. T√™n h√†m \"mo_rong_tu_viet_tat\" trong ti·∫øng Vi·ªát c√≥ th·ªÉ ƒë∆∞·ª£c d·ªãch l√† \"expand_abbreviations\" ho·∫∑c \"mo_rong_tu_viet_tat\" n·∫øu b·∫°n mu·ªën gi·ªØ nguy√™n t√™n g·ªëc.\n",
    "\n",
    "C√°ch ho·∫°t ƒë·ªông c·ªßa h√†m n√†y l√† s·ª≠ d·ª•ng m·ªôt th∆∞ vi·ªán ho·∫∑c t·ª´ ƒëi·ªÉn c√≥ s·∫µn (c√≥ th·ªÉ l√† contractions) ƒë·ªÉ t√¨m v√† thay th·∫ø c√°c t·ª´ vi·∫øt t·∫Øt trong vƒÉn b·∫£n b·∫±ng phi√™n b·∫£n ƒë·∫ßy ƒë·ªß c·ªßa t·ª´ ho·∫∑c c·ª•m t·ª´ ƒë√≥. V√≠ d·ª•:\n",
    "\n",
    "\"I'm\" s·∫Ω ƒë∆∞·ª£c m·ªü r·ªông th√†nh \"I am\".\n",
    "\"can't\" s·∫Ω ƒë∆∞·ª£c m·ªü r·ªông th√†nh \"cannot\".\n",
    "\"you'll\" s·∫Ω ƒë∆∞·ª£c m·ªü r·ªông th√†nh \"you will\".\n",
    "M·ª•c ti√™u c·ªßa h√†m n√†y l√† gi√∫p d·ªÖ d√†ng ƒë·ªçc v√† hi·ªÉu n·ªôi dung vƒÉn b·∫£n b·∫±ng vi·ªác lo·∫°i b·ªè c√°c t·ª´ vi·∫øt t·∫Øt v√† chuy·ªÉn ch√∫ng th√†nh phi√™n b·∫£n ƒë·∫ßy ƒë·ªß c·ªßa c√°c t·ª´ v√† c·ª•m t·ª´ t∆∞∆°ng ·ª©ng.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import contractions\n",
    "\n",
    "# ƒê·ªçc d·ªØ li·ªáu t·ª´ t·ªáp CSV\n",
    "with open('dataset3.csv', 'r', newline='') as input_file:\n",
    "    csv_reader = csv.DictReader(input_file)\n",
    "    data = []\n",
    "\n",
    "    # ƒê·ªãnh nghƒ©a h√†m ƒë·ªÉ m·ªü r·ªông t·ª´ vi·∫øt t·∫Øt\n",
    "    def mo_rong_tu_viet_tat(text):\n",
    "        return contractions.fix(text)\n",
    "\n",
    "    # Duy·ªát qua t·ª´ng d√≤ng d·ªØ li·ªáu trong t·ªáp ngu·ªìn v√† m·ªü r·ªông t·ª´ vi·∫øt t·∫Øt\n",
    "    for row in csv_reader:\n",
    "        row['Title'] = mo_rong_tu_viet_tat(row['Title'])\n",
    "        row['Excerpt'] = mo_rong_tu_viet_tat(row['Excerpt'])\n",
    "        row['Pub_Date'] = mo_rong_tu_viet_tat(row['Pub_Date'])\n",
    "        data.append(row)\n",
    "\n",
    "# L∆∞u d·ªØ li·ªáu ƒë√£ m·ªü r·ªông ra m·ªôt t·ªáp CSV m·ªõi\n",
    "with open('dataset4.csv', 'w', newline='') as output_file:\n",
    "    fieldnames = ['Title', 'Excerpt', 'Pub_Date']\n",
    "    csv_writer = csv.DictWriter(output_file, fieldnames=fieldnames)\n",
    "\n",
    "    csv_writer.writeheader()\n",
    "    csv_writer.writerows(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5)  Remove special characters (b·ªè k√≠ t·ª± ƒë·∫∑c bi·ªát)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \n",
    "H√†m loai_bo_ky_tu_dac_biet ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ lo·∫°i b·ªè c√°c k√Ω t·ª± ƒë·∫∑c bi·ªát (k√Ω t·ª± kh√¥ng ph·∫£i l√† ch·ªØ c√°i ho·∫∑c s·ªë) t·ª´ m·ªôt chu·ªói vƒÉn b·∫£n. H√†m n√†y s·ª≠ d·ª•ng bi·ªÉu th·ª©c ch√≠nh quy (regular expression) ƒë·ªÉ th·ª±c hi·ªán vi·ªác n√†y. D∆∞·ªõi ƒë√¢y l√† c√°ch n√≥ ho·∫°t ƒë·ªông:\n",
    "\n",
    "ƒê·∫ßu v√†o c·ªßa h√†m loai_bo_ky_tu_dac_biet l√† m·ªôt chu·ªói vƒÉn b·∫£n m√† b·∫°n mu·ªën lo·∫°i b·ªè c√°c k√Ω t·ª± ƒë·∫∑c bi·ªát kh·ªèi.\n",
    "\n",
    "Trong h√†m n√†y, bi·ªÉu th·ª©c ch√≠nh quy r'[^a-zA-Z0-9\\s]' ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ x√°c ƒë·ªãnh c√°c k√Ω t·ª± ƒë·∫∑c bi·ªát. ƒê√¢y l√† c√°ch gi·∫£i th√≠ch t·ª´ng ph·∫ßn:\n",
    "\n",
    "^ ·ªü ƒë·∫ßu bi·ªÉu th·ª©c ch√≠nh quy bi·ªÉu th·ªã \"kh√¥ng ph·∫£i\" ho·∫∑c \"lo·∫°i tr·ª´\". V√¨ v·∫≠y, [^a-zA-Z0-9\\s] nghƒ©a l√† \"kh√¥ng ph·∫£i l√† ch·ªØ c√°i ho·∫∑c s·ªë ho·∫∑c kho·∫£ng tr·∫Øng\".\n",
    "a-zA-Z ƒë·∫°i di·ªán cho t·∫•t c·∫£ c√°c k√Ω t·ª± ch·ªØ c√°i ti·∫øng Anh (k·ªÉ c·∫£ ch·ªØ hoa v√† ch·ªØ th∆∞·ªùng).\n",
    "0-9 ƒë·∫°i di·ªán cho t·∫•t c·∫£ c√°c ch·ªØ s·ªë.\n",
    "\\s ƒë·∫°i di·ªán cho kho·∫£ng tr·∫Øng (space).\n",
    "S·ª≠ d·ª•ng re.sub, t·∫•t c·∫£ c√°c k√Ω t·ª± kh·ªõp v·ªõi bi·ªÉu th·ª©c ch√≠nh quy s·∫Ω ƒë∆∞·ª£c thay th·∫ø b·∫±ng chu·ªói r·ªóng '', c√≥ nghƒ©a l√† n√≥ s·∫Ω b·ªã lo·∫°i b·ªè kh·ªèi chu·ªói vƒÉn b·∫£n.\n",
    "\n",
    "K·∫øt qu·∫£ c·ªßa h√†m loai_bo_ky_tu_dac_biet l√† chu·ªói vƒÉn b·∫£n kh√¥ng ch·ª©a c√°c k√Ω t·ª± ƒë·∫∑c bi·ªát.\n",
    "\n",
    "H√†m n√†y c√≥ th·ªÉ ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ l√†m s·∫°ch ho·∫∑c chu·∫©n h√≥a d·ªØ li·ªáu vƒÉn b·∫£n, ƒë·ªÉ d·ªÖ d√†ng x·ª≠ l√Ω ho·∫∑c ph√¢n t√≠ch n√≥ m√† kh√¥ng c·∫ßn quan t√¢m ƒë·∫øn c√°c k√Ω t·ª± ƒë·∫∑c bi·ªát"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "\n",
    "# ƒê·ªçc d·ªØ li·ªáu t·ª´ t·ªáp CSV\n",
    "with open('dataset4.csv', 'r', newline='') as input_file:\n",
    "    csv_reader = csv.DictReader(input_file)\n",
    "    data = []\n",
    "\n",
    "    # ƒê·ªãnh nghƒ©a h√†m ƒë·ªÉ lo·∫°i b·ªè k√Ω t·ª± ƒë·∫∑c bi·ªát\n",
    "    def loai_bo_ky_tu_dac_biet(text):\n",
    "        # S·ª≠ d·ª•ng bi·ªÉu th·ª©c ch√≠nh quy ƒë·ªÉ ch·ªâ gi·ªØ l·∫°i c√°c k√Ω t·ª± ch·ªØ v√† s·ªë\n",
    "        return re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "\n",
    "    # Duy·ªát qua t·ª´ng d√≤ng d·ªØ li·ªáu trong t·ªáp ngu·ªìn v√† lo·∫°i b·ªè k√Ω t·ª± ƒë·∫∑c bi·ªát\n",
    "    for row in csv_reader:\n",
    "        row['Title'] = loai_bo_ky_tu_dac_biet(row['Title'])\n",
    "        row['Excerpt'] = loai_bo_ky_tu_dac_biet(row['Excerpt'])\n",
    "        row['Pub_Date'] = loai_bo_ky_tu_dac_biet(row['Pub_Date'])\n",
    "        data.append(row)\n",
    "\n",
    "# L∆∞u d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω ra m·ªôt t·ªáp CSV m·ªõi\n",
    "with open('dataset5.csv', 'w', newline='') as output_file:\n",
    "    fieldnames = ['Title', 'Excerpt', 'Pub_Date']\n",
    "    csv_writer = csv.DictWriter(output_file, fieldnames=fieldnames)\n",
    "\n",
    "    csv_writer.writeheader()\n",
    "    csv_writer.writerows(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Text lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "Lemmatization l√† qu√° tr√¨nh chuy·ªÉn ƒë·ªïi c√°c t·ª´ trong vƒÉn b·∫£n th√†nh c√°c t·ª´ g·ªëc c·ªßa ch√∫ng (g·ªçi l√† lemma) ƒë·ªÉ d·ªÖ d√†ng so s√°nh v√† ph√¢n t√≠ch. Trong ti·∫øng Anh, lemmatization th∆∞·ªùng d·ª±a tr√™n t·ª´ ƒëi·ªÉn ƒë·ªÉ t√¨m c√°c t·ª´ g·ªëc. D∆∞·ªõi ƒë√¢y l√† c√°ch b·∫°n c√≥ th·ªÉ √°p d·ª•ng lemmatization cho d·ªØ li·ªáu trong c·ªôt \"Title\" c·ªßa t·ªáp CSV c·ªßa b·∫°n b·∫±ng s·ª≠ d·ª•ng th∆∞ vi·ªán NLTK (Natural Language Toolkit):\n",
    "\n",
    "ƒêo·∫°n m√£ lemmatize_text th·ª±c hi·ªán c√°c b∆∞·ªõc sau:\n",
    "\n",
    "tokens = word_tokenize(text): H√†m word_tokenize t·ª´ th∆∞ vi·ªán Natural Language Toolkit (NLTK) ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ t√°ch chu·ªói text th√†nh danh s√°ch c√°c t·ª´. V√≠ d·ª•, chu·ªói \"Create a series of posts\" s·∫Ω ƒë∆∞·ª£c chuy·ªÉn th√†nh danh s√°ch [\"Create\", \"a\", \"series\", \"of\", \"posts\"].\n",
    "\n",
    "lemmatized_tokens = [lemmatizer.lemmatize(word) for word in tokens]: Duy·ªát qua t·ª´ng t·ª´ trong danh s√°ch tokens v√† √°p d·ª•ng ph∆∞∆°ng th·ª©c lemmatize t·ª´ ƒë·ªëi t∆∞·ª£ng lemmatizer l√™n t·ª´ng t·ª´. Ph∆∞∆°ng th·ª©c lemmatize s·∫Ω lemmatize t·ª´ng t·ª´, nghƒ©a l√† chuy·ªÉn t·ª´ v·ªÅ d·∫°ng g·ªëc c·ªßa n√≥. V√≠ d·ª•, \"posts\" c√≥ th·ªÉ tr·ªü th√†nh \"post\" sau khi lemmatize.\n",
    "\n",
    "return ' '.join(lemmatized_tokens): Sau khi lemmatize t·ª´ng t·ª´, ch√∫ng ta k·∫øt h·ª£p l·∫°i c√°c t·ª´ th√†nh m·ªôt chu·ªói b·∫±ng c√°ch s·ª≠ d·ª•ng kho·∫£ng tr·∫Øng ' ' nh∆∞ d·∫•u ph√¢n c√°ch. ƒêi·ªÅu n√†y t·∫°o ra chu·ªói ƒë√£ lemmatize.\n",
    "\n",
    "V√≠ d·ª•: N·∫øu b·∫°n g·ªçi lemmatize_text(\"Create a series of posts\"), n√≥ s·∫Ω tr·∫£ v·ªÅ chu·ªói \"Create a series of post\" sau khi lemmatize.\n",
    "\n",
    "\n",
    "\n",
    "Trong qu√° tr√¨nh lemmatization, c√°c t·ª´ trong ti√™u ƒë·ªÅ v√† ph·∫ßn t√≥m t·∫Øt ƒë√£ ƒë∆∞·ª£c ƒë∆∞a v·ªÅ d·∫°ng nguy√™n m·∫´u (lemma), t·ª©c l√† d·∫°ng c∆° b·∫£n c·ªßa t·ª´ ƒë√≥, ch·∫≥ng h·∫°n \"Consuming\" ƒë√£ ƒë∆∞·ª£c chuy·ªÉn th√†nh \"Consume\", \"responsibly\" th√†nh \"responsibly\", \"Etiquette\" th√†nh \"Etiquette\", v√† c·ª© nh∆∞ v·∫≠y.\n",
    "\n",
    "L∆∞u √Ω r·∫±ng vi·ªác lemmatization s·∫Ω t√πy thu·ªôc v√†o lo·∫°i ng√¥n ng·ªØ m√† b·∫°n s·ª≠ d·ª•ng. Trong v√≠ d·ª• tr√™n, ng√¥n ng·ªØ c·ªßa vƒÉn b·∫£n l√† ti·∫øng Anh. ƒê·ªëi v·ªõi ti·∫øng Vi·ªát, qu√° tr√¨nh n√†y c√≥ th·ªÉ s·ª≠ d·ª•ng m·ªôt th∆∞ vi·ªán ti·∫øng Vi·ªát nh∆∞ pyvi ƒë·ªÉ th·ª±c hi·ªán t∆∞∆°ng t·ª±."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c lemmatized v√† l∆∞u v√†o t·ªáp lemmatized_dataset.csv.\n"
     ]
    }
   ],
   "source": [
    "#import nltk\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('punkt')\n",
    "import nltk\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "\"\"\"WordNetLemmatizer l√† m·ªôt c√¥ng c·ª• trong th∆∞ vi·ªán Natural Language Toolkit (NLTK) d√πng ƒë·ªÉ th·ª±c hi·ªán lemmatization, t·ª©c l√† chuy·ªÉn ƒë·ªïi t·ª´ v·ª±ng v·ªÅ d·∫°ng g·ªëc c·ªßa ch√∫ng.\n",
    "\n",
    "word_tokenize l√† m·ªôt h√†m trong nltk ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ t√°ch m·ªôt ƒëo·∫°n vƒÉn b·∫£n th√†nh danh s√°ch c√°c t·ª´ ri√™ng l·∫ª. Th∆∞·ªùng ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ chu·∫©n h√≥a v√† x·ª≠ l√Ω d·ªØ li·ªáu vƒÉn b·∫£n, ƒë·∫∑c bi·ªát l√† khi th·ª±c hi·ªán x·ª≠ l√Ω ng√¥n ng·ªØ t·ª± nhi√™n (NLP).\"\"\"\n",
    "import csv\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# ƒê∆∞·ªùng d·∫´n ƒë·∫øn t·ªáp CSV ƒë·∫ßu v√†o v√† ƒë·∫ßu ra\n",
    "input_csv_file = 'dataset5.csv'\n",
    "output_csv_file = 'dataset6.csv'\n",
    "\n",
    "# T·∫°o m·ªôt ƒë·ªëi t∆∞·ª£ng lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# H√†m lemmatization cho m·ªôt chu·ªói\n",
    "def lemmatize_text(text):\n",
    "    tokens = word_tokenize(text)  # T√°ch chu·ªói th√†nh danh s√°ch c√°c t·ª´\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in tokens]  # Lemmatize t·ª´ng t·ª´\n",
    "    return ' '.join(lemmatized_tokens)  # K·∫øt h·ª£p c√°c t·ª´ th√†nh chu·ªói\n",
    "\n",
    "# M·ªü t·ªáp ngu·ªìn ƒë·ªÉ ƒë·ªçc\n",
    "with open(input_csv_file, mode='r', newline='') as input_file:\n",
    "    reader = csv.reader(input_file)\n",
    "\n",
    "    # ƒê·ªçc d√≤ng ti√™u ƒë·ªÅ\n",
    "    header = next(reader)\n",
    "\n",
    "    # M·ªü t·ªáp ƒë√≠ch ƒë·ªÉ ghi\n",
    "    with open(output_csv_file, mode='w', newline='') as output_file:\n",
    "        writer = csv.writer(output_file)\n",
    "\n",
    "        # Ghi d√≤ng ti√™u ƒë·ªÅ\n",
    "        writer.writerow(header)\n",
    "\n",
    "        # Duy·ªát qua t·ª´ng d√≤ng d·ªØ li·ªáu trong t·ªáp ngu·ªìn\n",
    "        for row in reader:\n",
    "            # Lemmatize n·ªôi dung c·ªôt \"Title\"\n",
    "            lemmatized_title = lemmatize_text(row[0])\n",
    "            row[0] = lemmatized_title  # C·∫≠p nh·∫≠t l·∫°i c·ªôt \"Title\"\n",
    "\n",
    "            # Lemmatize n·ªôi dung c·ªôt \"Excerpt\"\n",
    "            lemmatized_excerpt = lemmatize_text(row[1])\n",
    "            row[1] = lemmatized_excerpt  # C·∫≠p nh·∫≠t l·∫°i c·ªôt \"Excerpt\"\n",
    "\n",
    "            # Lemmatize n·ªôi dung c·ªôt \"Pub_Date\"\n",
    "            lemmatized_excerpt = lemmatize_text(row[2])\n",
    "            row[2] = lemmatized_excerpt  # C·∫≠p nh·∫≠t l·∫°i c·ªôt \"Pub_Date\"\n",
    "\n",
    "            # Ghi d·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω v√†o t·ªáp ƒë√≠ch\n",
    "            writer.writerow(row)\n",
    "\n",
    "print(\"D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c lemmatized v√† l∆∞u v√†o t·ªáp lemmatized_dataset.csv.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 120 entries, 0 to 119\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Title     120 non-null    object\n",
      " 1   Excerpt   120 non-null    object\n",
      " 2   Pub_Date  120 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 2.9+ KB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('dataset6.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7) Text stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####\n",
    "M√£ tr√™n l√† v√≠ d·ª• v·ªÅ c√°ch s·ª≠ d·ª•ng stemming trong x·ª≠ l√Ω vƒÉn b·∫£n. Stemming l√† m·ªôt qu√° tr√¨nh c·∫Øt b·ªõt c√°c h·∫≠u t·ªë c·ªßa c√°c t·ª´ ƒë·ªÉ gi·ªØ l·∫°i t·ª´ g·ªëc ho·∫∑c stem c·ªßa t·ª´ ƒë√≥. Stemming gi√∫p chu·∫©n h√≥a vƒÉn b·∫£n b·∫±ng c√°ch lo·∫°i b·ªè c√°c bi·∫øn th·ªÉ t·ª´ c·ªßa m·ªôt t·ª´ g·ªëc, gi√∫p c√°c t·ª´ c√≥ nghƒ©a t∆∞∆°ng t·ª± nh∆∞ \"run\", \"running\", \"ran\" tr·ªü th√†nh c√πng m·ªôt t·ª´ \"run\".\n",
    "\n",
    "Trong v√≠ d·ª• n√†y:\n",
    "\n",
    "PorterStemmer() l√† m·ªôt ƒë·ªëi t∆∞·ª£ng stemmer ƒë∆∞·ª£c s·ª≠ d·ª•ng, trong tr∆∞·ªùng h·ª£p n√†y, ƒë√≥ l√† Porter Stemmer, m·ªôt trong nh·ªØng thu·∫≠t to√°n stemming ph·ªï bi·∫øn.\n",
    "\n",
    "H√†m stem_text(text) nh·∫≠n m·ªôt c√¢u ho·∫∑c m·ªôt ƒëo·∫°n vƒÉn b·∫£n (bi·ªÉu ƒë·∫°ng d∆∞·ªõi d·∫°ng chu·ªói) v√† th·ª±c hi·ªán stemming tr√™n n√≥.\n",
    "\n",
    "H√†m n√†y s·∫Ω t√°ch c√¢u th√†nh c√°c t·ª´ (s·ª≠ d·ª•ng word_tokenize t·ª´ th∆∞ vi·ªán NLTK), sau ƒë√≥ th·ª±c hi·ªán stemming cho m·ªói t·ª´ trong c√¢u v√† k·∫øt h·ª£p ch√∫ng l·∫°i ƒë·ªÉ t·∫°o m·ªôt c√¢u m·ªõi ch·ªâ ch·ª©a c√°c t·ª´ g·ªëc sau khi stemming.\n",
    "\n",
    "V√≠ d·ª• n√†y ch·ªâ √°p d·ª•ng stemming cho m·ªói t·ª´ trong vƒÉn b·∫£n, nh∆∞ng th∆∞·ªùng th√¨ n√≥ s·∫Ω ƒë∆∞·ª£c √°p d·ª•ng cho t·∫•t c·∫£ c√°c t·ª´ trong m·ªôt t√†i li·ªáu ho·∫∑c b·ªô d·ªØ li·ªáu ƒë·ªÉ chu·∫©n h√≥a vƒÉn b·∫£n tr∆∞·ªõc khi s·ª≠ d·ª•ng trong c√°c t√°c v·ª• x·ª≠ l√Ω ng√¥n ng·ªØ t·ª± nhi√™n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "\n",
    "# ƒê·ªçc d·ªØ li·ªáu t·ª´ t·ªáp CSV\n",
    "data = pd.read_csv('dataset6.csv')  # Thay 'data.csv' b·∫±ng t√™n t·ªáp CSV ch·ª©a d·ªØ li·ªáu c·ªßa b·∫°n\n",
    "\n",
    "# Kh·ªüi t·∫°o Stemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# T·∫°o m·ªôt h√†m ƒë·ªÉ th·ª±c hi·ªán stemming cho m·ªôt c√¢u\n",
    "def stem_text(text):\n",
    "    words = word_tokenize(text)#ƒê√¢y l√† m·ªôt h√†m t·ª´ th∆∞ vi·ªán NLTK (Natural Language Toolkit) ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ t√°ch chu·ªói vƒÉn b·∫£n th√†nh danh s√°ch c√°c t·ª´ (list of words). K·∫øt qu·∫£ l√† m·ªôt danh s√°ch, trong ƒë√≥ m·ªói ph·∫ßn t·ª≠ l√† m·ªôt t·ª´ ri√™ng l·∫ª trong chu·ªói vƒÉn b·∫£n.\n",
    "    #stemmed_words c√≥ t√°c d·ª•ng √°p d·ª•ng qu√° tr√¨nh stemming l√™n t·ª´ng t·ª´ trong danh s√°ch c√°c t·ª´ ƒë√£ ƒë∆∞·ª£c t√°ch t·ª´ vƒÉn b·∫£n.\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]#stemmer.stem(word): ƒê√¢y l√† m·ªôt ph·∫ßn c·ªßa qu√° tr√¨nh stemming. ƒê·ªëi t∆∞·ª£ng stemmer (c√≥ th·ªÉ l√† m·ªôt stemmer c·ª• th·ªÉ nh∆∞ PorterStemmer trong tr∆∞·ªùng h·ª£p n√†y) l√† m·ªôt ph·∫ßn m·ªÅm ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ chuy·ªÉn ƒë·ªïi c√°c t·ª´ v·ªÅ d·∫°ng c∆° b·∫£n ho·∫∑c g·ªëc c·ªßa ch√∫ng. Stemming lo·∫°i b·ªè c√°c h·∫≠u t·ªë (suffix) c·ªßa t·ª´ ƒë·ªÉ gi√∫p ƒë·ªìng nh·∫•t h√≥a c√°c t·ª´ c√≥ c√πng ngu·ªìn g·ªëc. V√≠ d·ª•: t·ª´ \"programming\" c√≥ th·ªÉ ƒë∆∞·ª£c ƒë∆∞a v·ªÅ d·∫°ng \"program.\"      word trong v√≤ng l·∫∑p: ƒê√¢y l√† t·ª´ng t·ª´ trong danh s√°ch words (danh s√°ch c√°c t·ª´ ƒë√£ ƒë∆∞·ª£c t√°ch t·ª´ vƒÉn b·∫£n).\n",
    "    #D√≤ng m√£ return ' '.join(stemmed_words) c√≥ nhi·ªám v·ª• gom c√°c t·ª´ trong danh s√°ch stemmed_words th√†nh m·ªôt chu·ªói duy nh·∫•t, c√°ch nhau b·ªüi kho·∫£ng tr·∫Øng.\n",
    "    return ' '.join(stemmed_words)\n",
    "\n",
    "# √Åp d·ª•ng h√†m stemming cho t·∫•t c·∫£ 3 c·ªôt\n",
    "data['Stemmed_Title'] = data['Title'].apply(stem_text)\n",
    "data['Stemmed_Excerpt'] = data['Excerpt'].apply(stem_text)\n",
    "data['Stemmed_Pub_Date'] = data['Pub_Date'].apply(stem_text)\n",
    "\n",
    "last_three_columns = data.iloc[:, -3:]  # S·ª≠ d·ª•ng ch·ªâ s·ªë c·ªôt\n",
    "# L∆∞u d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c stemming v√†o m·ªôt t·ªáp CSV m·ªõi\n",
    "data.to_csv('dataset7.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ƒê·ªçc t·ªáp CSV\n",
    "data = pd.read_csv('dataset7.csv')\n",
    "\n",
    "# Ch·ªçn 3 c·ªôt cu·ªëi c√πng (v√≠ d·ª•: Stemmed_Title,Stemmed_Excerpt,Stemmed_Pub_Date)\n",
    "selected_columns = data.iloc[:, -3:]\n",
    "\n",
    "# L∆∞u k·∫øt qu·∫£ v√†o m·ªôt t·ªáp CSV m·ªõi\n",
    "selected_columns.to_csv('dataset7New.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8)  Remove stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \n",
    "Stopwords l√† nh·ªØng t·ª´ ph·ªï bi·∫øn trong ng√¥n ng·ªØ m√† trong nhi·ªÅu tr∆∞·ªùng h·ª£p kh√¥ng mang nhi·ªÅu √Ω nghƒ©a ho·∫∑c th√¥ng tin quan tr·ªçng khi x·ª≠ l√Ω ng√¥n ng·ªØ t·ª± nhi√™n. C√°c t·ª´ n√†y th∆∞·ªùng ƒë∆∞·ª£c lo·∫°i b·ªè kh·ªèi vƒÉn b·∫£n ƒë·ªÉ l√†m cho d·ªØ li·ªáu g·ªçn h∆°n v√† gi·∫£m nhi·ªÖu trong qu√° tr√¨nh x·ª≠ l√Ω ng√¥n ng·ªØ.\n",
    "\n",
    "V√≠ d·ª• v·ªÅ stopwords trong ti·∫øng Anh bao g·ªìm \"the,\" \"and,\" \"of,\" \"in,\" \"to,\" v√† nhi·ªÅu t·ª´ kh√°c. Tuy nhi√™n, danh s√°ch stopwords c√≥ th·ªÉ thay ƒë·ªïi t√πy theo ng·ªØ c·∫£nh v√† nhi·ªám v·ª• c·ª• th·ªÉ. Khi th·ª±c hi·ªán x·ª≠ l√Ω ng√¥n ng·ªØ t·ª± nhi√™n, lo·∫°i b·ªè stopwords gi√∫p t·∫≠p trung v√†o nh·ªØng t·ª´ quan tr·ªçng h∆°n v√† c·∫£i thi·ªán hi·ªáu su·∫•t c·ªßa c√°c m√¥ h√¨nh ho·∫∑c t√°c v·ª• x·ª≠ l√Ω ng√¥n ng·ªØ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "#T·∫£i b·ªô d·ªØ li·ªáu stopwords v√† c√°c t√†i li·ªáu kh√°c b·∫±ng c√°ch ch·∫°y m√£ sau trong Python:\n",
    "#import nltk\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# ƒê·ªçc t·ªáp CSV\n",
    "data = pd.read_csv('dataset7New.csv')\n",
    "\n",
    "# T·∫£i danh s√°ch stopwords ti·∫øng Anh t·ª´ NLTK\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# H√†m lo·∫°i b·ªè stopwords t·ª´ m·ªôt vƒÉn b·∫£n\n",
    "def remove_stopwords(text):\n",
    "    words = word_tokenize(text)\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "# √Åp d·ª•ng h√†m lo·∫°i b·ªè stopwords cho t·ª´ng c·ªôt\n",
    "data['Stemmed_Title'] = data['Stemmed_Title'].apply(remove_stopwords)\n",
    "data['Stemmed_Excerpt'] = data['Stemmed_Excerpt'].apply(remove_stopwords)\n",
    "data['Stemmed_Pub_Date'] = data['Stemmed_Pub_Date'].apply(remove_stopwords)\n",
    "\n",
    "# Ch·ªçn 3 c·ªôt cu·ªëi c√πng \n",
    "selected_columns = data.iloc[:, -3:]\n",
    "\n",
    "# L∆∞u k·∫øt qu·∫£ v√†o m·ªôt t·ªáp CSV m·ªõi\n",
    "selected_columns.to_csv('dataset8.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9)  Building a text normalizer \n",
    "######\n",
    "Building a text normalizer\" kh√¥ng ph·∫£i l√† m·ªôt thu·∫≠t ng·ªØ k·ªπ thu·∫≠t c·ª• th·ªÉ trong lƒ©nh v·ª±c x·ª≠ l√Ω ng√¥n ng·ªØ t·ª± nhi√™n (NLP) ho·∫∑c khoa h·ªçc m√°y t√≠nh. Tuy nhi√™n, n√≥ c√≥ th·ªÉ √°m ch·ªâ ƒë·∫øn vi·ªác t·∫°o ra m·ªôt ·ª©ng d·ª•ng ho·∫∑c h·ªá th·ªëng ƒë·ªÉ chu·∫©n h√≥a vƒÉn b·∫£n ho·∫∑c vƒÉn b·∫£n trong qu√° tr√¨nh x·ª≠ l√Ω ng√¥n ng·ªØ t·ª± nhi√™n.\n",
    "\n",
    "Text normalization l√† qu√° tr√¨nh bi·∫øn ƒë·ªïi vƒÉn b·∫£n ƒë·ªÉ ƒë∆∞a v·ªÅ d·∫°ng chu·∫©n h√≥a, gi√∫p gi·∫£m thi·ªÉu s·ª± ƒëa d·∫°ng trong ng√¥n ng·ªØ v√† l√†m cho d·ªØ li·ªáu d·ªÖ d√†ng x·ª≠ l√Ω h∆°n. Text normalization bao g·ªìm nhi·ªÅu t√°c v·ª• nh∆∞:\n",
    "\n",
    "**Chuy·ªÉn ch·ªØ hoa th√†nh ch·ªØ th∆∞·ªùng:** ƒê·∫£m b·∫£o r·∫±ng t·∫•t c·∫£ c√°c k√Ω t·ª± ƒë·ªÅu ·ªü d·∫°ng ch·ªØ th∆∞·ªùng ƒë·ªÉ tr√°nh s·ª± ƒëa d·∫°ng do vi·ªác s·ª≠ d·ª•ng k√Ω t·ª± hoa.\n",
    "\n",
    "**Lo·∫°i b·ªè k√Ω t·ª± ƒë·∫∑c bi·ªát:** Lo·∫°i b·ªè c√°c k√Ω t·ª± ƒë·∫∑c bi·ªát nh∆∞ d·∫•u c√¢u, k√Ω t·ª± ƒë·∫∑c bi·ªát kh·ªèi vƒÉn b·∫£n.\n",
    "\n",
    "**Lo·∫°i b·ªè stopwords:** Lo·∫°i b·ªè c√°c t·ª´ ph·ªï bi·∫øn nh∆∞ \"v√†,\" \"ho·∫∑c,\" \"m·ªôt s·ªë,\" v.v. ƒë·ªÉ t·∫≠p trung v√†o c√°c t·ª´ quan tr·ªçng h∆°n.\n",
    "\n",
    "**Lemmatisation v√† stemming:** Chuy·ªÉn t·ª´ v·ªÅ d·∫°ng c∆° b·∫£n ho·∫∑c gi·∫£m t·ª´ v·ªÅ d·∫°ng g·ªëc c·ªßa n√≥.\n",
    "\n",
    "**X·ª≠ l√Ω s·ªë li·ªáu:** Chu·∫©n h√≥a v√† x·ª≠ l√Ω s·ªë li·ªáu trong vƒÉn b·∫£n.\n",
    "\n",
    "V√¨ v·∫≠y, \"building a text normalizer\" c√≥ th·ªÉ ƒë·ªÅ c·∫≠p ƒë·∫øn vi·ªác ph√°t tri·ªÉn ho·∫∑c x√¢y d·ª±ng m·ªôt h·ªá th·ªëng ho·∫∑c m√£ ngu·ªìn ƒë·ªÉ th·ª±c hi·ªán c√°c t√°c v·ª• chu·∫©n h√≥a vƒÉn b·∫£n nh∆∞ nh·ªØng ƒëi·ªÅu ƒë√£ n√™u tr√™n. C√°c ·ª©ng d·ª•ng NLP th∆∞·ªùng s·ª≠ d·ª•ng c√°c b∆∞·ªõc chu·∫©n h√≥a vƒÉn b·∫£n nh∆∞ v·∫≠y ƒë·ªÉ chu·∫©n h√≥a d·ªØ li·ªáu ƒë·∫ßu v√†o v√† l√†m cho n√≥ d·ªÖ d√†ng x·ª≠ l√Ω h∆°n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
